graph(%self.1 : ClassType<robert>,
      %tokens.1 : Long(*)):
  %4 : bool = prim::Constant[value=1]()
  %5 : bool = prim::Constant[value=0]()
  %8 : None = prim::Constant()
  %10 : int = prim::Constant[value=1]()
  %11 : int = prim::Constant[value=0]()
  %12 : int = prim::Constant[value=-1]()
  %14 : float = prim::Constant[value=1e-05]()
  %15 : float = prim::Constant[value=0.1]()
  %tokens0.1 : Long(*, *) = aten::unsqueeze(%tokens.1, %11)
  %25 : ClassType<encoder> = prim::GetAttr[name="encoder"](%self.1)
  %26 : int = prim::GetAttr[name="padding_idx"](%25)
  %padding_mask.1 : BoolTensor = aten::eq(%tokens0.1, %26)
  %3072 : ClassType<token_embedding> = prim::GetAttr[name="token_embedding"](%25)
  %3073 : Float(*, *) = prim::GetAttr[name="weight"](%3072)
  %embedded.1 : Tensor = aten::embedding(%3073, %tokens0.1, %10, %5, %5)
  %48 : ClassType<positional_embedding> = prim::GetAttr[name="positional_embedding"](%25)
  %49 : int = prim::GetAttr[name="padding_idx"](%48)
  %50 : BoolTensor = aten::ne(%tokens0.1, %49)
  %masked.1 : LongTensor = aten::_cast_Long(%50, %5)
  %52 : Tensor = aten::cumsum(%masked.1, %10, %8)
  %3074 : Tensor = aten::mul(%52, %masked.1)
  %positions.1 : Tensor = aten::add(%3074, %49, %10)
  %3077 : ClassType<embedding> = prim::GetAttr[name="embedding"](%48)
  %3078 : Float(*, *) = prim::GetAttr[name="weight"](%3077)
  %embedded_positions.1 : Tensor = aten::embedding(%3078, %positions.1, %10, %5, %5)
  %3079 : ClassType<embedding_layer_norm> = prim::GetAttr[name="embedding_layer_norm"](%25)
  %3081 : Tensor = aten::add(%embedded.1, %embedded_positions.1, %10)
  %3082 : Float(*) = prim::GetAttr[name="weight"](%3079)
  %3083 : Float(*) = prim::GetAttr[name="bias"](%3079)
  %3084 : int[] = prim::Constant[value=[768]]()
  %normed.1 : Tensor = aten::layer_norm(%3081, %3084, %3082, %3083, %14, %4)
  %3088 : ClassType<dropout> = prim::GetAttr[name="dropout"](%25)
  %3089 : bool = prim::GetAttr[name="training"](%3088)
  %normed0.2 : Tensor = aten::dropout(%normed.1, %15, %3089)
  %89 : Tensor = aten::unsqueeze(%padding_mask.1, %12)
  %padded_normed.1 : Tensor = prim::FusionGroup_0(%normed0.2, %89)
  %encoded11.1 : Tensor, %encoded10.1 : Tensor, %encoded9.1 : Tensor, %encoded8.1 : Tensor, %encoded7.1 : Tensor, %encoded6.1 : Tensor, %encoded5.1 : Tensor, %encoded4.1 : Tensor, %encoded3.1 : Tensor, %encoded2.1 : Tensor, %encoded1.1 : Tensor, %encoded0.1 : Tensor, %encoded.1 : Tensor = glow::FusionGroup_1(%padding_mask.1, %25, %padded_normed.1)
  %all_layers.1 : Tensor[] = prim::ListConstruct(%encoded.1)
  %314 : Tensor[] = aten::append(%all_layers.1, %encoded0.1)
  %520 : Tensor[] = aten::append(%all_layers.1, %encoded1.1)
  %726 : Tensor[] = aten::append(%all_layers.1, %encoded2.1)
  %932 : Tensor[] = aten::append(%all_layers.1, %encoded3.1)
  %1138 : Tensor[] = aten::append(%all_layers.1, %encoded4.1)
  %1344 : Tensor[] = aten::append(%all_layers.1, %encoded5.1)
  %1550 : Tensor[] = aten::append(%all_layers.1, %encoded6.1)
  %1756 : Tensor[] = aten::append(%all_layers.1, %encoded7.1)
  %1962 : Tensor[] = aten::append(%all_layers.1, %encoded8.1)
  %2168 : Tensor[] = aten::append(%all_layers.1, %encoded9.1)
  %2374 : Tensor[] = aten::append(%all_layers.1, %encoded10.1)
  %2580 : Tensor[] = aten::append(%all_layers.1, %encoded11.1)
  %last_layer.1 : Tensor = aten::__getitem__(%all_layers.1, %12)
  %2582 : Tensor = aten::transpose(%last_layer.1, %11, %10)
  return (%2582)
with prim::FusionGroup_0 = graph(%0 : Tensor,
      %8 : Tensor):
  %4 : int = prim::Constant[value=1]()
  %9 : Tensor = aten::type_as(%8, %0)
  %7 : Tensor = aten::neg(%9)
  %5 : Tensor = aten::add(%7, %4, %4)
  %padded_normed.1 : Tensor = aten::mul(%0, %5)
  return (%padded_normed.1)
with glow::FusionGroup_1 = graph(%208 : BoolTensor,
      %2577 : ClassType<encoder>,
      %2579 : Tensor):
  %2580 : int = prim::Constant[value=0]()
  %2581 : int = prim::Constant[value=1]()
  %encoded.1 : Tensor = aten::transpose(%2579, %2580, %2581)
  %2578 : ClassType<layers> = prim::GetAttr[name="layers"](%2577)
  %2576 : ClassType<_0> = prim::GetAttr[name="0"](%2578)
  %2575 : ClassType<_1> = prim::GetAttr[name="1"](%2578)
  %2574 : ClassType<_2> = prim::GetAttr[name="2"](%2578)
  %2573 : ClassType<_3> = prim::GetAttr[name="3"](%2578)
  %2572 : ClassType<_4> = prim::GetAttr[name="4"](%2578)
  %2571 : ClassType<_5> = prim::GetAttr[name="5"](%2578)
  %2570 : ClassType<_6> = prim::GetAttr[name="6"](%2578)
  %2569 : ClassType<_7> = prim::GetAttr[name="7"](%2578)
  %2568 : ClassType<_8> = prim::GetAttr[name="8"](%2578)
  %2567 : ClassType<_9> = prim::GetAttr[name="9"](%2578)
  %2566 : ClassType<_10> = prim::GetAttr[name="10"](%2578)
  %2565 : ClassType<_11> = prim::GetAttr[name="11"](%2578)
  %2563 : ClassType<attention> = prim::GetAttr[name="attention"](%2576)
  %2562 : int[] = aten::size(%encoded.1)
  %tgt_len.1 : int, %bsz.1 : int, %embed_dim.1 : int = prim::ListUnpack(%2562)
  %2557 : int[] = aten::size(%208)
  %mask_bsz.1 : int, %src_len.1 : int = prim::ListUnpack(%2557)
  %2553 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%2563)
  %2552 : Float(*, *) = prim::GetAttr[name="weight"](%2553)
  %2551 : Float(*) = prim::GetAttr[name="bias"](%2553)
  %2547 : int = prim::Constant[value=2]()
  %2548 : int = prim::Constant[value=1]()
  %projection : Tensor = glow::fused_linear(%encoded.1, %2552, %2551, %2547, %2548)
  %2542 : Tensor, %2543 : Tensor, %2544 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection)
  %2540 : float = prim::GetAttr[name="scaling"](%2563)
  %q0.1 : Tensor = aten::mul_(%2542, %2540)
  %2535 : int = prim::Constant[value=0]()
  %2536 : Tensor = aten::contiguous(%q0.1, %2535)
  %2533 : int = prim::GetAttr[name="num_heads"](%2563)
  %2532 : int = aten::mul(%bsz.1, %2533)
  %2531 : int = prim::GetAttr[name="head_dim"](%2563)
  %2530 : int[] = prim::ListConstruct(%tgt_len.1, %2532, %2531)
  %2529 : Tensor(*, *, *) = aten::view(%2536, %2530)
  %2524 : int = prim::Constant[value=0]()
  %2525 : int = prim::Constant[value=1]()
  %q1.1 : Tensor(*, *, *) = aten::transpose(%2529, %2524, %2525)
  %2521 : int = prim::Constant[value=0]()
  %2522 : Tensor = aten::contiguous(%2543, %2521)
  %2518 : int = prim::Constant[value=-1]()
  %2519 : int[] = prim::ListConstruct(%2518, %2532, %2531)
  %2517 : Tensor(*, *, *) = aten::view(%2522, %2519)
  %2512 : int = prim::Constant[value=0]()
  %2513 : int = prim::Constant[value=1]()
  %k0.1 : Tensor(*, *, *) = aten::transpose(%2517, %2512, %2513)
  %2509 : int = prim::Constant[value=0]()
  %2510 : Tensor = aten::contiguous(%2544, %2509)
  %2505 : int = prim::Constant[value=-1]()
  %2507 : int[] = prim::ListConstruct(%2505, %2532, %2531)
  %2504 : Tensor(*, *, *) = aten::view(%2510, %2507)
  %2499 : int = prim::Constant[value=0]()
  %2500 : int = prim::Constant[value=1]()
  %v0.1 : Tensor(*, *, *) = aten::transpose(%2504, %2499, %2500)
  %2495 : int = prim::Constant[value=1]()
  %2496 : int = prim::Constant[value=2]()
  %2497 : Tensor(*, *, *) = aten::transpose(%k0.1, %2495, %2496)
  %attn_weights.1 : Tensor(*, *, *) = aten::bmm(%q1.1, %2497)
  %2490 : int[] = prim::ListConstruct(%bsz.1, %2533, %tgt_len.1, %src_len.1)
  %attn_weights0.1 : Tensor(*, *, *, *) = aten::view(%attn_weights.1, %2490)
  %2484 : int = prim::Constant[value=1]()
  %2485 : Tensor = aten::unsqueeze(%208, %2484)
  %2482 : int = prim::Constant[value=2]()
  %2483 : Tensor = aten::unsqueeze(%2485, %2482)
  %2479 : float = prim::Constant[value=-inf]()
  %attn_weights1.1 : Tensor = aten::masked_fill(%attn_weights0.1, %2483, %2479)
  %2477 : int[] = prim::ListConstruct(%2532, %tgt_len.1, %src_len.1)
  %attn_weights2.1 : Tensor(*, *, *) = aten::view(%attn_weights1.1, %2477)
  %2469 : int = prim::Constant[value=-1]()
  %2470 : int = prim::Constant[value=6]()
  %ret.2 : Tensor = aten::softmax(%attn_weights2.1, %2469, %2470)
  %attn_weights3.1 : Tensor = aten::type_as(%ret.2, %attn_weights2.1)
  %2465 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2563)
  %2464 : bool = prim::GetAttr[name="training"](%2465)
  %2460 : float = prim::Constant[value=0.1]()
  %attn_weights4.2 : Tensor = aten::dropout(%attn_weights3.1, %2460, %2464)
  %attn.1 : Tensor(*, *, *) = aten::bmm(%attn_weights4.2, %v0.1)
  %2453 : int = prim::Constant[value=0]()
  %2454 : int = prim::Constant[value=1]()
  %2455 : Tensor(*, *, *) = aten::transpose(%attn.1, %2453, %2454)
  %2450 : int = prim::Constant[value=0]()
  %2451 : Tensor(*, *, *) = aten::contiguous(%2455, %2450)
  %2448 : int[] = prim::ListConstruct(%tgt_len.1, %bsz.1, %embed_dim.1)
  %attn0.1 : Tensor(*, *, *) = aten::view(%2451, %2448)
  %2441 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%2563)
  %2439 : Float(*, *) = prim::GetAttr[name="weight"](%2441)
  %2438 : Float(*) = prim::GetAttr[name="bias"](%2441)
  %2436 : Float(*, *) = aten::t(%2439)
  %output1.1 : Tensor(*, *, *) = aten::matmul(%attn0.1, %2436)
  %2430 : int = prim::Constant[value=1]()
  %output2.1 : Tensor = aten::add_(%output1.1, %2438, %2430)
  %2427 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2576)
  %2426 : bool = prim::GetAttr[name="training"](%2427)
  %2422 : float = prim::Constant[value=0.1]()
  %attention0.2 : Tensor = aten::dropout(%output2.1, %2422, %2426)
  %2419 : int = prim::Constant[value=1]()
  %biased_input.1 : Tensor = aten::add(%encoded.1, %attention0.2, %2419)
  %2416 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2576)
  %2415 : Float(*) = prim::GetAttr[name="weight"](%2416)
  %2414 : Float(*) = prim::GetAttr[name="bias"](%2416)
  %2407 : int[] = prim::Constant[value=[768]]()
  %2410 : float = prim::Constant[value=1e-05]()
  %2411 : bool = prim::Constant[value=1]()
  %biased_input0.1 : Tensor = aten::layer_norm(%biased_input.1, %2407, %2415, %2414, %2410, %2411)
  %2405 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2576)
  %2404 : ClassType<mlp> = prim::GetAttr[name="mlp"](%2405)
  %2402 : ClassType<_0> = prim::GetAttr[name="0"](%2404)
  %2401 : ClassType<_2> = prim::GetAttr[name="2"](%2404)
  %2400 : ClassType<_3> = prim::GetAttr[name="3"](%2404)
  %2399 : ClassType<_4> = prim::GetAttr[name="4"](%2404)
  %2397 : Float(*, *) = prim::GetAttr[name="weight"](%2402)
  %2396 : Float(*) = prim::GetAttr[name="bias"](%2402)
  %2392 : int = prim::Constant[value=2]()
  %2393 : int = prim::Constant[value=1]()
  %input1 : Tensor = glow::fused_linear(%biased_input0.1, %2397, %2396, %2392, %2393)
  %2388 : bool = prim::Constant[value=0]()
  %2389 : FloatTensor = aten::_cast_Float(%input1, %2388)
  %2387 : FloatTensor = aten::gelu(%2389)
  %input2.1 : Tensor = aten::type_as(%2387, %input1)
  %2382 : bool = prim::GetAttr[name="training"](%2401)
  %2378 : float = prim::Constant[value=0.1]()
  %input3.2 : Tensor = aten::dropout(%input2.1, %2378, %2382)
  %2376 : Float(*, *) = prim::GetAttr[name="weight"](%2400)
  %2375 : Float(*) = prim::GetAttr[name="bias"](%2400)
  %2371 : int = prim::Constant[value=2]()
  %2372 : int = prim::Constant[value=1]()
  %input4 : Tensor = glow::fused_linear(%input3.2, %2376, %2375, %2371, %2372)
  %2367 : bool = prim::GetAttr[name="training"](%2399)
  %2363 : float = prim::Constant[value=0.1]()
  %bias7.2 : Tensor = aten::dropout(%input4, %2363, %2367)
  %2360 : int = prim::Constant[value=1]()
  %biased.1 : Tensor = aten::add(%biased_input0.1, %bias7.2, %2360)
  %2357 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2576)
  %2355 : Float(*) = prim::GetAttr[name="weight"](%2357)
  %2354 : Float(*) = prim::GetAttr[name="bias"](%2357)
  %2347 : int[] = prim::Constant[value=[768]]()
  %2350 : float = prim::Constant[value=1e-05]()
  %2351 : bool = prim::Constant[value=1]()
  %encoded0.1 : Tensor = aten::layer_norm(%biased.1, %2347, %2355, %2354, %2350, %2351)
  %2345 : ClassType<attention> = prim::GetAttr[name="attention"](%2575)
  %2344 : int[] = aten::size(%encoded0.1)
  %tgt_len0.1 : int, %bsz0.1 : int, %embed_dim0.1 : int = prim::ListUnpack(%2344)
  %2339 : int[] = aten::size(%208)
  %mask_bsz0.1 : int, %src_len0.1 : int = prim::ListUnpack(%2339)
  %2335 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%2345)
  %2334 : Float(*, *) = prim::GetAttr[name="weight"](%2335)
  %2333 : Float(*) = prim::GetAttr[name="bias"](%2335)
  %2329 : int = prim::Constant[value=2]()
  %2330 : int = prim::Constant[value=1]()
  %projection0 : Tensor = glow::fused_linear(%encoded0.1, %2334, %2333, %2329, %2330)
  %2324 : Tensor, %2325 : Tensor, %2326 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection0)
  %2322 : float = prim::GetAttr[name="scaling"](%2345)
  %q3.1 : Tensor = aten::mul_(%2324, %2322)
  %2317 : int = prim::Constant[value=0]()
  %2318 : Tensor = aten::contiguous(%q3.1, %2317)
  %2315 : int = prim::GetAttr[name="num_heads"](%2345)
  %2314 : int = aten::mul(%bsz0.1, %2315)
  %2313 : int = prim::GetAttr[name="head_dim"](%2345)
  %2312 : int[] = prim::ListConstruct(%tgt_len0.1, %2314, %2313)
  %2311 : Tensor(*, *, *) = aten::view(%2318, %2312)
  %2306 : int = prim::Constant[value=0]()
  %2307 : int = prim::Constant[value=1]()
  %q4.1 : Tensor(*, *, *) = aten::transpose(%2311, %2306, %2307)
  %2303 : int = prim::Constant[value=0]()
  %2304 : Tensor = aten::contiguous(%2325, %2303)
  %2300 : int = prim::Constant[value=-1]()
  %2301 : int[] = prim::ListConstruct(%2300, %2314, %2313)
  %2299 : Tensor(*, *, *) = aten::view(%2304, %2301)
  %2294 : int = prim::Constant[value=0]()
  %2295 : int = prim::Constant[value=1]()
  %k2.1 : Tensor(*, *, *) = aten::transpose(%2299, %2294, %2295)
  %2291 : int = prim::Constant[value=0]()
  %2292 : Tensor = aten::contiguous(%2326, %2291)
  %2287 : int = prim::Constant[value=-1]()
  %2289 : int[] = prim::ListConstruct(%2287, %2314, %2313)
  %2286 : Tensor(*, *, *) = aten::view(%2292, %2289)
  %2281 : int = prim::Constant[value=0]()
  %2282 : int = prim::Constant[value=1]()
  %v2.1 : Tensor(*, *, *) = aten::transpose(%2286, %2281, %2282)
  %2277 : int = prim::Constant[value=1]()
  %2278 : int = prim::Constant[value=2]()
  %2279 : Tensor(*, *, *) = aten::transpose(%k2.1, %2277, %2278)
  %attn_weights5.1 : Tensor(*, *, *) = aten::bmm(%q4.1, %2279)
  %2272 : int[] = prim::ListConstruct(%bsz0.1, %2315, %tgt_len0.1, %src_len0.1)
  %attn_weights6.1 : Tensor(*, *, *, *) = aten::view(%attn_weights5.1, %2272)
  %2266 : float = prim::Constant[value=-inf]()
  %attn_weights7.1 : Tensor = aten::masked_fill(%attn_weights6.1, %2483, %2266)
  %2264 : int[] = prim::ListConstruct(%2314, %tgt_len0.1, %src_len0.1)
  %attn_weights8.1 : Tensor(*, *, *) = aten::view(%attn_weights7.1, %2264)
  %2256 : int = prim::Constant[value=-1]()
  %2257 : int = prim::Constant[value=6]()
  %ret0.2 : Tensor = aten::softmax(%attn_weights8.1, %2256, %2257)
  %attn_weights9.1 : Tensor = aten::type_as(%ret0.2, %attn_weights8.1)
  %2252 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2345)
  %2251 : bool = prim::GetAttr[name="training"](%2252)
  %2247 : float = prim::Constant[value=0.1]()
  %attn_weights10.2 : Tensor = aten::dropout(%attn_weights9.1, %2247, %2251)
  %attn1.1 : Tensor(*, *, *) = aten::bmm(%attn_weights10.2, %v2.1)
  %2240 : int = prim::Constant[value=0]()
  %2241 : int = prim::Constant[value=1]()
  %2242 : Tensor(*, *, *) = aten::transpose(%attn1.1, %2240, %2241)
  %2237 : int = prim::Constant[value=0]()
  %2238 : Tensor(*, *, *) = aten::contiguous(%2242, %2237)
  %2235 : int[] = prim::ListConstruct(%tgt_len0.1, %bsz0.1, %embed_dim0.1)
  %attn2.1 : Tensor(*, *, *) = aten::view(%2238, %2235)
  %2228 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%2345)
  %2226 : Float(*, *) = prim::GetAttr[name="weight"](%2228)
  %2225 : Float(*) = prim::GetAttr[name="bias"](%2228)
  %2223 : Float(*, *) = aten::t(%2226)
  %output9.1 : Tensor(*, *, *) = aten::matmul(%attn2.1, %2223)
  %2217 : int = prim::Constant[value=1]()
  %output10.1 : Tensor = aten::add_(%output9.1, %2225, %2217)
  %2214 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2575)
  %2213 : bool = prim::GetAttr[name="training"](%2214)
  %2209 : float = prim::Constant[value=0.1]()
  %attention2.2 : Tensor = aten::dropout(%output10.1, %2209, %2213)
  %2206 : int = prim::Constant[value=1]()
  %biased_input1.1 : Tensor = aten::add(%encoded0.1, %attention2.2, %2206)
  %2203 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2575)
  %2202 : Float(*) = prim::GetAttr[name="weight"](%2203)
  %2201 : Float(*) = prim::GetAttr[name="bias"](%2203)
  %2194 : int[] = prim::Constant[value=[768]]()
  %2197 : float = prim::Constant[value=1e-05]()
  %2198 : bool = prim::Constant[value=1]()
  %biased_input2.1 : Tensor = aten::layer_norm(%biased_input1.1, %2194, %2202, %2201, %2197, %2198)
  %2192 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2575)
  %2191 : ClassType<mlp> = prim::GetAttr[name="mlp"](%2192)
  %2189 : ClassType<_0> = prim::GetAttr[name="0"](%2191)
  %2188 : ClassType<_2> = prim::GetAttr[name="2"](%2191)
  %2187 : ClassType<_3> = prim::GetAttr[name="3"](%2191)
  %2186 : ClassType<_4> = prim::GetAttr[name="4"](%2191)
  %2184 : Float(*, *) = prim::GetAttr[name="weight"](%2189)
  %2183 : Float(*) = prim::GetAttr[name="bias"](%2189)
  %2179 : int = prim::Constant[value=2]()
  %2180 : int = prim::Constant[value=1]()
  %input5 : Tensor = glow::fused_linear(%biased_input2.1, %2184, %2183, %2179, %2180)
  %2175 : bool = prim::Constant[value=0]()
  %2176 : FloatTensor = aten::_cast_Float(%input5, %2175)
  %2174 : FloatTensor = aten::gelu(%2176)
  %input6.1 : Tensor = aten::type_as(%2174, %input5)
  %2169 : bool = prim::GetAttr[name="training"](%2188)
  %2165 : float = prim::Constant[value=0.1]()
  %input7.2 : Tensor = aten::dropout(%input6.1, %2165, %2169)
  %2163 : Float(*, *) = prim::GetAttr[name="weight"](%2187)
  %2162 : Float(*) = prim::GetAttr[name="bias"](%2187)
  %2158 : int = prim::Constant[value=2]()
  %2159 : int = prim::Constant[value=1]()
  %input8 : Tensor = glow::fused_linear(%input7.2, %2163, %2162, %2158, %2159)
  %2154 : bool = prim::GetAttr[name="training"](%2186)
  %2150 : float = prim::Constant[value=0.1]()
  %bias16.2 : Tensor = aten::dropout(%input8, %2150, %2154)
  %2147 : int = prim::Constant[value=1]()
  %biased0.1 : Tensor = aten::add(%biased_input2.1, %bias16.2, %2147)
  %2144 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2575)
  %2142 : Float(*) = prim::GetAttr[name="weight"](%2144)
  %2141 : Float(*) = prim::GetAttr[name="bias"](%2144)
  %2134 : int[] = prim::Constant[value=[768]]()
  %2137 : float = prim::Constant[value=1e-05]()
  %2138 : bool = prim::Constant[value=1]()
  %encoded1.1 : Tensor = aten::layer_norm(%biased0.1, %2134, %2142, %2141, %2137, %2138)
  %2132 : ClassType<attention> = prim::GetAttr[name="attention"](%2574)
  %2131 : int[] = aten::size(%encoded1.1)
  %tgt_len1.1 : int, %bsz1.1 : int, %embed_dim1.1 : int = prim::ListUnpack(%2131)
  %2126 : int[] = aten::size(%208)
  %mask_bsz1.1 : int, %src_len1.1 : int = prim::ListUnpack(%2126)
  %2122 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%2132)
  %2121 : Float(*, *) = prim::GetAttr[name="weight"](%2122)
  %2120 : Float(*) = prim::GetAttr[name="bias"](%2122)
  %2116 : int = prim::Constant[value=2]()
  %2117 : int = prim::Constant[value=1]()
  %projection1 : Tensor = glow::fused_linear(%encoded1.1, %2121, %2120, %2116, %2117)
  %2111 : Tensor, %2112 : Tensor, %2113 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection1)
  %2109 : float = prim::GetAttr[name="scaling"](%2132)
  %q6.1 : Tensor = aten::mul_(%2111, %2109)
  %2104 : int = prim::Constant[value=0]()
  %2105 : Tensor = aten::contiguous(%q6.1, %2104)
  %2102 : int = prim::GetAttr[name="num_heads"](%2132)
  %2101 : int = aten::mul(%bsz1.1, %2102)
  %2100 : int = prim::GetAttr[name="head_dim"](%2132)
  %2099 : int[] = prim::ListConstruct(%tgt_len1.1, %2101, %2100)
  %2098 : Tensor(*, *, *) = aten::view(%2105, %2099)
  %2093 : int = prim::Constant[value=0]()
  %2094 : int = prim::Constant[value=1]()
  %q7.1 : Tensor(*, *, *) = aten::transpose(%2098, %2093, %2094)
  %2090 : int = prim::Constant[value=0]()
  %2091 : Tensor = aten::contiguous(%2112, %2090)
  %2087 : int = prim::Constant[value=-1]()
  %2088 : int[] = prim::ListConstruct(%2087, %2101, %2100)
  %2086 : Tensor(*, *, *) = aten::view(%2091, %2088)
  %2081 : int = prim::Constant[value=0]()
  %2082 : int = prim::Constant[value=1]()
  %k4.1 : Tensor(*, *, *) = aten::transpose(%2086, %2081, %2082)
  %2078 : int = prim::Constant[value=0]()
  %2079 : Tensor = aten::contiguous(%2113, %2078)
  %2074 : int = prim::Constant[value=-1]()
  %2076 : int[] = prim::ListConstruct(%2074, %2101, %2100)
  %2073 : Tensor(*, *, *) = aten::view(%2079, %2076)
  %2068 : int = prim::Constant[value=0]()
  %2069 : int = prim::Constant[value=1]()
  %v4.1 : Tensor(*, *, *) = aten::transpose(%2073, %2068, %2069)
  %2064 : int = prim::Constant[value=1]()
  %2065 : int = prim::Constant[value=2]()
  %2066 : Tensor(*, *, *) = aten::transpose(%k4.1, %2064, %2065)
  %attn_weights11.1 : Tensor(*, *, *) = aten::bmm(%q7.1, %2066)
  %2059 : int[] = prim::ListConstruct(%bsz1.1, %2102, %tgt_len1.1, %src_len1.1)
  %attn_weights12.1 : Tensor(*, *, *, *) = aten::view(%attn_weights11.1, %2059)
  %2053 : float = prim::Constant[value=-inf]()
  %attn_weights13.1 : Tensor = aten::masked_fill(%attn_weights12.1, %2483, %2053)
  %2051 : int[] = prim::ListConstruct(%2101, %tgt_len1.1, %src_len1.1)
  %attn_weights14.1 : Tensor(*, *, *) = aten::view(%attn_weights13.1, %2051)
  %2043 : int = prim::Constant[value=-1]()
  %2044 : int = prim::Constant[value=6]()
  %ret1.2 : Tensor = aten::softmax(%attn_weights14.1, %2043, %2044)
  %attn_weights15.1 : Tensor = aten::type_as(%ret1.2, %attn_weights14.1)
  %2039 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2132)
  %2038 : bool = prim::GetAttr[name="training"](%2039)
  %2034 : float = prim::Constant[value=0.1]()
  %attn_weights16.2 : Tensor = aten::dropout(%attn_weights15.1, %2034, %2038)
  %attn3.1 : Tensor(*, *, *) = aten::bmm(%attn_weights16.2, %v4.1)
  %2027 : int = prim::Constant[value=0]()
  %2028 : int = prim::Constant[value=1]()
  %2029 : Tensor(*, *, *) = aten::transpose(%attn3.1, %2027, %2028)
  %2024 : int = prim::Constant[value=0]()
  %2025 : Tensor(*, *, *) = aten::contiguous(%2029, %2024)
  %2022 : int[] = prim::ListConstruct(%tgt_len1.1, %bsz1.1, %embed_dim1.1)
  %attn4.1 : Tensor(*, *, *) = aten::view(%2025, %2022)
  %2015 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%2132)
  %2013 : Float(*, *) = prim::GetAttr[name="weight"](%2015)
  %2012 : Float(*) = prim::GetAttr[name="bias"](%2015)
  %2010 : Float(*, *) = aten::t(%2013)
  %output17.1 : Tensor(*, *, *) = aten::matmul(%attn4.1, %2010)
  %2004 : int = prim::Constant[value=1]()
  %output18.1 : Tensor = aten::add_(%output17.1, %2012, %2004)
  %2001 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2574)
  %2000 : bool = prim::GetAttr[name="training"](%2001)
  %1996 : float = prim::Constant[value=0.1]()
  %attention4.2 : Tensor = aten::dropout(%output18.1, %1996, %2000)
  %1993 : int = prim::Constant[value=1]()
  %biased_input3.1 : Tensor = aten::add(%encoded1.1, %attention4.2, %1993)
  %1990 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2574)
  %1989 : Float(*) = prim::GetAttr[name="weight"](%1990)
  %1988 : Float(*) = prim::GetAttr[name="bias"](%1990)
  %1981 : int[] = prim::Constant[value=[768]]()
  %1984 : float = prim::Constant[value=1e-05]()
  %1985 : bool = prim::Constant[value=1]()
  %biased_input4.1 : Tensor = aten::layer_norm(%biased_input3.1, %1981, %1989, %1988, %1984, %1985)
  %1979 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2574)
  %1978 : ClassType<mlp> = prim::GetAttr[name="mlp"](%1979)
  %1976 : ClassType<_0> = prim::GetAttr[name="0"](%1978)
  %1975 : ClassType<_2> = prim::GetAttr[name="2"](%1978)
  %1974 : ClassType<_3> = prim::GetAttr[name="3"](%1978)
  %1973 : ClassType<_4> = prim::GetAttr[name="4"](%1978)
  %1971 : Float(*, *) = prim::GetAttr[name="weight"](%1976)
  %1970 : Float(*) = prim::GetAttr[name="bias"](%1976)
  %1966 : int = prim::Constant[value=2]()
  %1967 : int = prim::Constant[value=1]()
  %input9 : Tensor = glow::fused_linear(%biased_input4.1, %1971, %1970, %1966, %1967)
  %1962 : bool = prim::Constant[value=0]()
  %1963 : FloatTensor = aten::_cast_Float(%input9, %1962)
  %1961 : FloatTensor = aten::gelu(%1963)
  %input10.1 : Tensor = aten::type_as(%1961, %input9)
  %1956 : bool = prim::GetAttr[name="training"](%1975)
  %1952 : float = prim::Constant[value=0.1]()
  %input11.2 : Tensor = aten::dropout(%input10.1, %1952, %1956)
  %1950 : Float(*, *) = prim::GetAttr[name="weight"](%1974)
  %1949 : Float(*) = prim::GetAttr[name="bias"](%1974)
  %1945 : int = prim::Constant[value=2]()
  %1946 : int = prim::Constant[value=1]()
  %input12 : Tensor = glow::fused_linear(%input11.2, %1950, %1949, %1945, %1946)
  %1941 : bool = prim::GetAttr[name="training"](%1973)
  %1937 : float = prim::Constant[value=0.1]()
  %bias25.2 : Tensor = aten::dropout(%input12, %1937, %1941)
  %1934 : int = prim::Constant[value=1]()
  %biased1.1 : Tensor = aten::add(%biased_input4.1, %bias25.2, %1934)
  %1931 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2574)
  %1929 : Float(*) = prim::GetAttr[name="weight"](%1931)
  %1928 : Float(*) = prim::GetAttr[name="bias"](%1931)
  %1921 : int[] = prim::Constant[value=[768]]()
  %1924 : float = prim::Constant[value=1e-05]()
  %1925 : bool = prim::Constant[value=1]()
  %encoded2.1 : Tensor = aten::layer_norm(%biased1.1, %1921, %1929, %1928, %1924, %1925)
  %1919 : ClassType<attention> = prim::GetAttr[name="attention"](%2573)
  %1918 : int[] = aten::size(%encoded2.1)
  %tgt_len2.1 : int, %bsz2.1 : int, %embed_dim2.1 : int = prim::ListUnpack(%1918)
  %1913 : int[] = aten::size(%208)
  %mask_bsz2.1 : int, %src_len2.1 : int = prim::ListUnpack(%1913)
  %1909 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%1919)
  %1908 : Float(*, *) = prim::GetAttr[name="weight"](%1909)
  %1907 : Float(*) = prim::GetAttr[name="bias"](%1909)
  %1903 : int = prim::Constant[value=2]()
  %1904 : int = prim::Constant[value=1]()
  %projection2 : Tensor = glow::fused_linear(%encoded2.1, %1908, %1907, %1903, %1904)
  %1898 : Tensor, %1899 : Tensor, %1900 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection2)
  %1896 : float = prim::GetAttr[name="scaling"](%1919)
  %q9.1 : Tensor = aten::mul_(%1898, %1896)
  %1891 : int = prim::Constant[value=0]()
  %1892 : Tensor = aten::contiguous(%q9.1, %1891)
  %1889 : int = prim::GetAttr[name="num_heads"](%1919)
  %1888 : int = aten::mul(%bsz2.1, %1889)
  %1887 : int = prim::GetAttr[name="head_dim"](%1919)
  %1886 : int[] = prim::ListConstruct(%tgt_len2.1, %1888, %1887)
  %1885 : Tensor(*, *, *) = aten::view(%1892, %1886)
  %1880 : int = prim::Constant[value=0]()
  %1881 : int = prim::Constant[value=1]()
  %q10.1 : Tensor(*, *, *) = aten::transpose(%1885, %1880, %1881)
  %1877 : int = prim::Constant[value=0]()
  %1878 : Tensor = aten::contiguous(%1899, %1877)
  %1874 : int = prim::Constant[value=-1]()
  %1875 : int[] = prim::ListConstruct(%1874, %1888, %1887)
  %1873 : Tensor(*, *, *) = aten::view(%1878, %1875)
  %1868 : int = prim::Constant[value=0]()
  %1869 : int = prim::Constant[value=1]()
  %k6.1 : Tensor(*, *, *) = aten::transpose(%1873, %1868, %1869)
  %1865 : int = prim::Constant[value=0]()
  %1866 : Tensor = aten::contiguous(%1900, %1865)
  %1861 : int = prim::Constant[value=-1]()
  %1863 : int[] = prim::ListConstruct(%1861, %1888, %1887)
  %1860 : Tensor(*, *, *) = aten::view(%1866, %1863)
  %1855 : int = prim::Constant[value=0]()
  %1856 : int = prim::Constant[value=1]()
  %v6.1 : Tensor(*, *, *) = aten::transpose(%1860, %1855, %1856)
  %1851 : int = prim::Constant[value=1]()
  %1852 : int = prim::Constant[value=2]()
  %1853 : Tensor(*, *, *) = aten::transpose(%k6.1, %1851, %1852)
  %attn_weights17.1 : Tensor(*, *, *) = aten::bmm(%q10.1, %1853)
  %1846 : int[] = prim::ListConstruct(%bsz2.1, %1889, %tgt_len2.1, %src_len2.1)
  %attn_weights18.1 : Tensor(*, *, *, *) = aten::view(%attn_weights17.1, %1846)
  %1840 : float = prim::Constant[value=-inf]()
  %attn_weights19.1 : Tensor = aten::masked_fill(%attn_weights18.1, %2483, %1840)
  %1838 : int[] = prim::ListConstruct(%1888, %tgt_len2.1, %src_len2.1)
  %attn_weights20.1 : Tensor(*, *, *) = aten::view(%attn_weights19.1, %1838)
  %1830 : int = prim::Constant[value=-1]()
  %1831 : int = prim::Constant[value=6]()
  %ret2.2 : Tensor = aten::softmax(%attn_weights20.1, %1830, %1831)
  %attn_weights21.1 : Tensor = aten::type_as(%ret2.2, %attn_weights20.1)
  %1826 : ClassType<dropout> = prim::GetAttr[name="dropout"](%1919)
  %1825 : bool = prim::GetAttr[name="training"](%1826)
  %1821 : float = prim::Constant[value=0.1]()
  %attn_weights22.2 : Tensor = aten::dropout(%attn_weights21.1, %1821, %1825)
  %attn5.1 : Tensor(*, *, *) = aten::bmm(%attn_weights22.2, %v6.1)
  %1814 : int = prim::Constant[value=0]()
  %1815 : int = prim::Constant[value=1]()
  %1816 : Tensor(*, *, *) = aten::transpose(%attn5.1, %1814, %1815)
  %1811 : int = prim::Constant[value=0]()
  %1812 : Tensor(*, *, *) = aten::contiguous(%1816, %1811)
  %1809 : int[] = prim::ListConstruct(%tgt_len2.1, %bsz2.1, %embed_dim2.1)
  %attn6.1 : Tensor(*, *, *) = aten::view(%1812, %1809)
  %1802 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%1919)
  %1800 : Float(*, *) = prim::GetAttr[name="weight"](%1802)
  %1799 : Float(*) = prim::GetAttr[name="bias"](%1802)
  %1797 : Float(*, *) = aten::t(%1800)
  %output25.1 : Tensor(*, *, *) = aten::matmul(%attn6.1, %1797)
  %1791 : int = prim::Constant[value=1]()
  %output26.1 : Tensor = aten::add_(%output25.1, %1799, %1791)
  %1788 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2573)
  %1787 : bool = prim::GetAttr[name="training"](%1788)
  %1783 : float = prim::Constant[value=0.1]()
  %attention6.2 : Tensor = aten::dropout(%output26.1, %1783, %1787)
  %1780 : int = prim::Constant[value=1]()
  %biased_input5.1 : Tensor = aten::add(%encoded2.1, %attention6.2, %1780)
  %1777 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2573)
  %1776 : Float(*) = prim::GetAttr[name="weight"](%1777)
  %1775 : Float(*) = prim::GetAttr[name="bias"](%1777)
  %1768 : int[] = prim::Constant[value=[768]]()
  %1771 : float = prim::Constant[value=1e-05]()
  %1772 : bool = prim::Constant[value=1]()
  %biased_input6.1 : Tensor = aten::layer_norm(%biased_input5.1, %1768, %1776, %1775, %1771, %1772)
  %1766 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2573)
  %1765 : ClassType<mlp> = prim::GetAttr[name="mlp"](%1766)
  %1763 : ClassType<_0> = prim::GetAttr[name="0"](%1765)
  %1762 : ClassType<_2> = prim::GetAttr[name="2"](%1765)
  %1761 : ClassType<_3> = prim::GetAttr[name="3"](%1765)
  %1760 : ClassType<_4> = prim::GetAttr[name="4"](%1765)
  %1758 : Float(*, *) = prim::GetAttr[name="weight"](%1763)
  %1757 : Float(*) = prim::GetAttr[name="bias"](%1763)
  %1753 : int = prim::Constant[value=2]()
  %1754 : int = prim::Constant[value=1]()
  %input13 : Tensor = glow::fused_linear(%biased_input6.1, %1758, %1757, %1753, %1754)
  %1749 : bool = prim::Constant[value=0]()
  %1750 : FloatTensor = aten::_cast_Float(%input13, %1749)
  %1748 : FloatTensor = aten::gelu(%1750)
  %input14.1 : Tensor = aten::type_as(%1748, %input13)
  %1743 : bool = prim::GetAttr[name="training"](%1762)
  %1739 : float = prim::Constant[value=0.1]()
  %input15.2 : Tensor = aten::dropout(%input14.1, %1739, %1743)
  %1737 : Float(*, *) = prim::GetAttr[name="weight"](%1761)
  %1736 : Float(*) = prim::GetAttr[name="bias"](%1761)
  %1732 : int = prim::Constant[value=2]()
  %1733 : int = prim::Constant[value=1]()
  %input16 : Tensor = glow::fused_linear(%input15.2, %1737, %1736, %1732, %1733)
  %1728 : bool = prim::GetAttr[name="training"](%1760)
  %1724 : float = prim::Constant[value=0.1]()
  %bias34.2 : Tensor = aten::dropout(%input16, %1724, %1728)
  %1721 : int = prim::Constant[value=1]()
  %biased2.1 : Tensor = aten::add(%biased_input6.1, %bias34.2, %1721)
  %1718 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2573)
  %1716 : Float(*) = prim::GetAttr[name="weight"](%1718)
  %1715 : Float(*) = prim::GetAttr[name="bias"](%1718)
  %1708 : int[] = prim::Constant[value=[768]]()
  %1711 : float = prim::Constant[value=1e-05]()
  %1712 : bool = prim::Constant[value=1]()
  %encoded3.1 : Tensor = aten::layer_norm(%biased2.1, %1708, %1716, %1715, %1711, %1712)
  %1706 : ClassType<attention> = prim::GetAttr[name="attention"](%2572)
  %1705 : int[] = aten::size(%encoded3.1)
  %tgt_len3.1 : int, %bsz3.1 : int, %embed_dim3.1 : int = prim::ListUnpack(%1705)
  %1700 : int[] = aten::size(%208)
  %mask_bsz3.1 : int, %src_len3.1 : int = prim::ListUnpack(%1700)
  %1696 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%1706)
  %1695 : Float(*, *) = prim::GetAttr[name="weight"](%1696)
  %1694 : Float(*) = prim::GetAttr[name="bias"](%1696)
  %1690 : int = prim::Constant[value=2]()
  %1691 : int = prim::Constant[value=1]()
  %projection3 : Tensor = glow::fused_linear(%encoded3.1, %1695, %1694, %1690, %1691)
  %1685 : Tensor, %1686 : Tensor, %1687 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection3)
  %1683 : float = prim::GetAttr[name="scaling"](%1706)
  %q12.1 : Tensor = aten::mul_(%1685, %1683)
  %1678 : int = prim::Constant[value=0]()
  %1679 : Tensor = aten::contiguous(%q12.1, %1678)
  %1676 : int = prim::GetAttr[name="num_heads"](%1706)
  %1675 : int = aten::mul(%bsz3.1, %1676)
  %1674 : int = prim::GetAttr[name="head_dim"](%1706)
  %1673 : int[] = prim::ListConstruct(%tgt_len3.1, %1675, %1674)
  %1672 : Tensor(*, *, *) = aten::view(%1679, %1673)
  %1667 : int = prim::Constant[value=0]()
  %1668 : int = prim::Constant[value=1]()
  %q13.1 : Tensor(*, *, *) = aten::transpose(%1672, %1667, %1668)
  %1664 : int = prim::Constant[value=0]()
  %1665 : Tensor = aten::contiguous(%1686, %1664)
  %1661 : int = prim::Constant[value=-1]()
  %1662 : int[] = prim::ListConstruct(%1661, %1675, %1674)
  %1660 : Tensor(*, *, *) = aten::view(%1665, %1662)
  %1655 : int = prim::Constant[value=0]()
  %1656 : int = prim::Constant[value=1]()
  %k8.1 : Tensor(*, *, *) = aten::transpose(%1660, %1655, %1656)
  %1652 : int = prim::Constant[value=0]()
  %1653 : Tensor = aten::contiguous(%1687, %1652)
  %1648 : int = prim::Constant[value=-1]()
  %1650 : int[] = prim::ListConstruct(%1648, %1675, %1674)
  %1647 : Tensor(*, *, *) = aten::view(%1653, %1650)
  %1642 : int = prim::Constant[value=0]()
  %1643 : int = prim::Constant[value=1]()
  %v8.1 : Tensor(*, *, *) = aten::transpose(%1647, %1642, %1643)
  %1638 : int = prim::Constant[value=1]()
  %1639 : int = prim::Constant[value=2]()
  %1640 : Tensor(*, *, *) = aten::transpose(%k8.1, %1638, %1639)
  %attn_weights23.1 : Tensor(*, *, *) = aten::bmm(%q13.1, %1640)
  %1633 : int[] = prim::ListConstruct(%bsz3.1, %1676, %tgt_len3.1, %src_len3.1)
  %attn_weights24.1 : Tensor(*, *, *, *) = aten::view(%attn_weights23.1, %1633)
  %1627 : float = prim::Constant[value=-inf]()
  %attn_weights25.1 : Tensor = aten::masked_fill(%attn_weights24.1, %2483, %1627)
  %1625 : int[] = prim::ListConstruct(%1675, %tgt_len3.1, %src_len3.1)
  %attn_weights26.1 : Tensor(*, *, *) = aten::view(%attn_weights25.1, %1625)
  %1617 : int = prim::Constant[value=-1]()
  %1618 : int = prim::Constant[value=6]()
  %ret3.2 : Tensor = aten::softmax(%attn_weights26.1, %1617, %1618)
  %attn_weights27.1 : Tensor = aten::type_as(%ret3.2, %attn_weights26.1)
  %1613 : ClassType<dropout> = prim::GetAttr[name="dropout"](%1706)
  %1612 : bool = prim::GetAttr[name="training"](%1613)
  %1608 : float = prim::Constant[value=0.1]()
  %attn_weights28.2 : Tensor = aten::dropout(%attn_weights27.1, %1608, %1612)
  %attn7.1 : Tensor(*, *, *) = aten::bmm(%attn_weights28.2, %v8.1)
  %1601 : int = prim::Constant[value=0]()
  %1602 : int = prim::Constant[value=1]()
  %1603 : Tensor(*, *, *) = aten::transpose(%attn7.1, %1601, %1602)
  %1598 : int = prim::Constant[value=0]()
  %1599 : Tensor(*, *, *) = aten::contiguous(%1603, %1598)
  %1596 : int[] = prim::ListConstruct(%tgt_len3.1, %bsz3.1, %embed_dim3.1)
  %attn8.1 : Tensor(*, *, *) = aten::view(%1599, %1596)
  %1589 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%1706)
  %1587 : Float(*, *) = prim::GetAttr[name="weight"](%1589)
  %1586 : Float(*) = prim::GetAttr[name="bias"](%1589)
  %1584 : Float(*, *) = aten::t(%1587)
  %output33.1 : Tensor(*, *, *) = aten::matmul(%attn8.1, %1584)
  %1578 : int = prim::Constant[value=1]()
  %output34.1 : Tensor = aten::add_(%output33.1, %1586, %1578)
  %1575 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2572)
  %1574 : bool = prim::GetAttr[name="training"](%1575)
  %1570 : float = prim::Constant[value=0.1]()
  %attention8.2 : Tensor = aten::dropout(%output34.1, %1570, %1574)
  %1567 : int = prim::Constant[value=1]()
  %biased_input7.1 : Tensor = aten::add(%encoded3.1, %attention8.2, %1567)
  %1564 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2572)
  %1563 : Float(*) = prim::GetAttr[name="weight"](%1564)
  %1562 : Float(*) = prim::GetAttr[name="bias"](%1564)
  %1555 : int[] = prim::Constant[value=[768]]()
  %1558 : float = prim::Constant[value=1e-05]()
  %1559 : bool = prim::Constant[value=1]()
  %biased_input8.1 : Tensor = aten::layer_norm(%biased_input7.1, %1555, %1563, %1562, %1558, %1559)
  %1553 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2572)
  %1552 : ClassType<mlp> = prim::GetAttr[name="mlp"](%1553)
  %1550 : ClassType<_0> = prim::GetAttr[name="0"](%1552)
  %1549 : ClassType<_2> = prim::GetAttr[name="2"](%1552)
  %1548 : ClassType<_3> = prim::GetAttr[name="3"](%1552)
  %1547 : ClassType<_4> = prim::GetAttr[name="4"](%1552)
  %1545 : Float(*, *) = prim::GetAttr[name="weight"](%1550)
  %1544 : Float(*) = prim::GetAttr[name="bias"](%1550)
  %1540 : int = prim::Constant[value=2]()
  %1541 : int = prim::Constant[value=1]()
  %input17 : Tensor = glow::fused_linear(%biased_input8.1, %1545, %1544, %1540, %1541)
  %1536 : bool = prim::Constant[value=0]()
  %1537 : FloatTensor = aten::_cast_Float(%input17, %1536)
  %1535 : FloatTensor = aten::gelu(%1537)
  %input18.1 : Tensor = aten::type_as(%1535, %input17)
  %1530 : bool = prim::GetAttr[name="training"](%1549)
  %1526 : float = prim::Constant[value=0.1]()
  %input19.2 : Tensor = aten::dropout(%input18.1, %1526, %1530)
  %1524 : Float(*, *) = prim::GetAttr[name="weight"](%1548)
  %1523 : Float(*) = prim::GetAttr[name="bias"](%1548)
  %1519 : int = prim::Constant[value=2]()
  %1520 : int = prim::Constant[value=1]()
  %input20 : Tensor = glow::fused_linear(%input19.2, %1524, %1523, %1519, %1520)
  %1515 : bool = prim::GetAttr[name="training"](%1547)
  %1511 : float = prim::Constant[value=0.1]()
  %bias43.2 : Tensor = aten::dropout(%input20, %1511, %1515)
  %1508 : int = prim::Constant[value=1]()
  %biased3.1 : Tensor = aten::add(%biased_input8.1, %bias43.2, %1508)
  %1505 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2572)
  %1503 : Float(*) = prim::GetAttr[name="weight"](%1505)
  %1502 : Float(*) = prim::GetAttr[name="bias"](%1505)
  %1495 : int[] = prim::Constant[value=[768]]()
  %1498 : float = prim::Constant[value=1e-05]()
  %1499 : bool = prim::Constant[value=1]()
  %encoded4.1 : Tensor = aten::layer_norm(%biased3.1, %1495, %1503, %1502, %1498, %1499)
  %1493 : ClassType<attention> = prim::GetAttr[name="attention"](%2571)
  %1492 : int[] = aten::size(%encoded4.1)
  %tgt_len4.1 : int, %bsz4.1 : int, %embed_dim4.1 : int = prim::ListUnpack(%1492)
  %1487 : int[] = aten::size(%208)
  %mask_bsz4.1 : int, %src_len4.1 : int = prim::ListUnpack(%1487)
  %1483 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%1493)
  %1482 : Float(*, *) = prim::GetAttr[name="weight"](%1483)
  %1481 : Float(*) = prim::GetAttr[name="bias"](%1483)
  %1477 : int = prim::Constant[value=2]()
  %1478 : int = prim::Constant[value=1]()
  %projection4 : Tensor = glow::fused_linear(%encoded4.1, %1482, %1481, %1477, %1478)
  %1472 : Tensor, %1473 : Tensor, %1474 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection4)
  %1470 : float = prim::GetAttr[name="scaling"](%1493)
  %q15.1 : Tensor = aten::mul_(%1472, %1470)
  %1465 : int = prim::Constant[value=0]()
  %1466 : Tensor = aten::contiguous(%q15.1, %1465)
  %1463 : int = prim::GetAttr[name="num_heads"](%1493)
  %1462 : int = aten::mul(%bsz4.1, %1463)
  %1461 : int = prim::GetAttr[name="head_dim"](%1493)
  %1460 : int[] = prim::ListConstruct(%tgt_len4.1, %1462, %1461)
  %1459 : Tensor(*, *, *) = aten::view(%1466, %1460)
  %1454 : int = prim::Constant[value=0]()
  %1455 : int = prim::Constant[value=1]()
  %q16.1 : Tensor(*, *, *) = aten::transpose(%1459, %1454, %1455)
  %1451 : int = prim::Constant[value=0]()
  %1452 : Tensor = aten::contiguous(%1473, %1451)
  %1448 : int = prim::Constant[value=-1]()
  %1449 : int[] = prim::ListConstruct(%1448, %1462, %1461)
  %1447 : Tensor(*, *, *) = aten::view(%1452, %1449)
  %1442 : int = prim::Constant[value=0]()
  %1443 : int = prim::Constant[value=1]()
  %k10.1 : Tensor(*, *, *) = aten::transpose(%1447, %1442, %1443)
  %1439 : int = prim::Constant[value=0]()
  %1440 : Tensor = aten::contiguous(%1474, %1439)
  %1435 : int = prim::Constant[value=-1]()
  %1437 : int[] = prim::ListConstruct(%1435, %1462, %1461)
  %1434 : Tensor(*, *, *) = aten::view(%1440, %1437)
  %1429 : int = prim::Constant[value=0]()
  %1430 : int = prim::Constant[value=1]()
  %v10.1 : Tensor(*, *, *) = aten::transpose(%1434, %1429, %1430)
  %1425 : int = prim::Constant[value=1]()
  %1426 : int = prim::Constant[value=2]()
  %1427 : Tensor(*, *, *) = aten::transpose(%k10.1, %1425, %1426)
  %attn_weights29.1 : Tensor(*, *, *) = aten::bmm(%q16.1, %1427)
  %1420 : int[] = prim::ListConstruct(%bsz4.1, %1463, %tgt_len4.1, %src_len4.1)
  %attn_weights30.1 : Tensor(*, *, *, *) = aten::view(%attn_weights29.1, %1420)
  %1414 : float = prim::Constant[value=-inf]()
  %attn_weights31.1 : Tensor = aten::masked_fill(%attn_weights30.1, %2483, %1414)
  %1412 : int[] = prim::ListConstruct(%1462, %tgt_len4.1, %src_len4.1)
  %attn_weights32.1 : Tensor(*, *, *) = aten::view(%attn_weights31.1, %1412)
  %1404 : int = prim::Constant[value=-1]()
  %1405 : int = prim::Constant[value=6]()
  %ret4.2 : Tensor = aten::softmax(%attn_weights32.1, %1404, %1405)
  %attn_weights33.1 : Tensor = aten::type_as(%ret4.2, %attn_weights32.1)
  %1400 : ClassType<dropout> = prim::GetAttr[name="dropout"](%1493)
  %1399 : bool = prim::GetAttr[name="training"](%1400)
  %1395 : float = prim::Constant[value=0.1]()
  %attn_weights34.2 : Tensor = aten::dropout(%attn_weights33.1, %1395, %1399)
  %attn9.1 : Tensor(*, *, *) = aten::bmm(%attn_weights34.2, %v10.1)
  %1388 : int = prim::Constant[value=0]()
  %1389 : int = prim::Constant[value=1]()
  %1390 : Tensor(*, *, *) = aten::transpose(%attn9.1, %1388, %1389)
  %1385 : int = prim::Constant[value=0]()
  %1386 : Tensor(*, *, *) = aten::contiguous(%1390, %1385)
  %1383 : int[] = prim::ListConstruct(%tgt_len4.1, %bsz4.1, %embed_dim4.1)
  %attn10.1 : Tensor(*, *, *) = aten::view(%1386, %1383)
  %1376 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%1493)
  %1374 : Float(*, *) = prim::GetAttr[name="weight"](%1376)
  %1373 : Float(*) = prim::GetAttr[name="bias"](%1376)
  %1371 : Float(*, *) = aten::t(%1374)
  %output41.1 : Tensor(*, *, *) = aten::matmul(%attn10.1, %1371)
  %1365 : int = prim::Constant[value=1]()
  %output42.1 : Tensor = aten::add_(%output41.1, %1373, %1365)
  %1362 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2571)
  %1361 : bool = prim::GetAttr[name="training"](%1362)
  %1357 : float = prim::Constant[value=0.1]()
  %attention10.2 : Tensor = aten::dropout(%output42.1, %1357, %1361)
  %1354 : int = prim::Constant[value=1]()
  %biased_input9.1 : Tensor = aten::add(%encoded4.1, %attention10.2, %1354)
  %1351 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2571)
  %1350 : Float(*) = prim::GetAttr[name="weight"](%1351)
  %1349 : Float(*) = prim::GetAttr[name="bias"](%1351)
  %1342 : int[] = prim::Constant[value=[768]]()
  %1345 : float = prim::Constant[value=1e-05]()
  %1346 : bool = prim::Constant[value=1]()
  %biased_input10.1 : Tensor = aten::layer_norm(%biased_input9.1, %1342, %1350, %1349, %1345, %1346)
  %1340 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2571)
  %1339 : ClassType<mlp> = prim::GetAttr[name="mlp"](%1340)
  %1337 : ClassType<_0> = prim::GetAttr[name="0"](%1339)
  %1336 : ClassType<_2> = prim::GetAttr[name="2"](%1339)
  %1335 : ClassType<_3> = prim::GetAttr[name="3"](%1339)
  %1334 : ClassType<_4> = prim::GetAttr[name="4"](%1339)
  %1332 : Float(*, *) = prim::GetAttr[name="weight"](%1337)
  %1331 : Float(*) = prim::GetAttr[name="bias"](%1337)
  %1327 : int = prim::Constant[value=2]()
  %1328 : int = prim::Constant[value=1]()
  %input21 : Tensor = glow::fused_linear(%biased_input10.1, %1332, %1331, %1327, %1328)
  %1323 : bool = prim::Constant[value=0]()
  %1324 : FloatTensor = aten::_cast_Float(%input21, %1323)
  %1322 : FloatTensor = aten::gelu(%1324)
  %input22.1 : Tensor = aten::type_as(%1322, %input21)
  %1317 : bool = prim::GetAttr[name="training"](%1336)
  %1313 : float = prim::Constant[value=0.1]()
  %input23.2 : Tensor = aten::dropout(%input22.1, %1313, %1317)
  %1311 : Float(*, *) = prim::GetAttr[name="weight"](%1335)
  %1310 : Float(*) = prim::GetAttr[name="bias"](%1335)
  %1306 : int = prim::Constant[value=2]()
  %1307 : int = prim::Constant[value=1]()
  %input24 : Tensor = glow::fused_linear(%input23.2, %1311, %1310, %1306, %1307)
  %1302 : bool = prim::GetAttr[name="training"](%1334)
  %1298 : float = prim::Constant[value=0.1]()
  %bias52.2 : Tensor = aten::dropout(%input24, %1298, %1302)
  %1295 : int = prim::Constant[value=1]()
  %biased4.1 : Tensor = aten::add(%biased_input10.1, %bias52.2, %1295)
  %1292 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2571)
  %1290 : Float(*) = prim::GetAttr[name="weight"](%1292)
  %1289 : Float(*) = prim::GetAttr[name="bias"](%1292)
  %1282 : int[] = prim::Constant[value=[768]]()
  %1285 : float = prim::Constant[value=1e-05]()
  %1286 : bool = prim::Constant[value=1]()
  %encoded5.1 : Tensor = aten::layer_norm(%biased4.1, %1282, %1290, %1289, %1285, %1286)
  %1280 : ClassType<attention> = prim::GetAttr[name="attention"](%2570)
  %1279 : int[] = aten::size(%encoded5.1)
  %tgt_len5.1 : int, %bsz5.1 : int, %embed_dim5.1 : int = prim::ListUnpack(%1279)
  %1274 : int[] = aten::size(%208)
  %mask_bsz5.1 : int, %src_len5.1 : int = prim::ListUnpack(%1274)
  %1270 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%1280)
  %1269 : Float(*, *) = prim::GetAttr[name="weight"](%1270)
  %1268 : Float(*) = prim::GetAttr[name="bias"](%1270)
  %1264 : int = prim::Constant[value=2]()
  %1265 : int = prim::Constant[value=1]()
  %projection5 : Tensor = glow::fused_linear(%encoded5.1, %1269, %1268, %1264, %1265)
  %1259 : Tensor, %1260 : Tensor, %1261 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection5)
  %1257 : float = prim::GetAttr[name="scaling"](%1280)
  %q18.1 : Tensor = aten::mul_(%1259, %1257)
  %1252 : int = prim::Constant[value=0]()
  %1253 : Tensor = aten::contiguous(%q18.1, %1252)
  %1250 : int = prim::GetAttr[name="num_heads"](%1280)
  %1249 : int = aten::mul(%bsz5.1, %1250)
  %1248 : int = prim::GetAttr[name="head_dim"](%1280)
  %1247 : int[] = prim::ListConstruct(%tgt_len5.1, %1249, %1248)
  %1246 : Tensor(*, *, *) = aten::view(%1253, %1247)
  %1241 : int = prim::Constant[value=0]()
  %1242 : int = prim::Constant[value=1]()
  %q19.1 : Tensor(*, *, *) = aten::transpose(%1246, %1241, %1242)
  %1238 : int = prim::Constant[value=0]()
  %1239 : Tensor = aten::contiguous(%1260, %1238)
  %1235 : int = prim::Constant[value=-1]()
  %1236 : int[] = prim::ListConstruct(%1235, %1249, %1248)
  %1234 : Tensor(*, *, *) = aten::view(%1239, %1236)
  %1229 : int = prim::Constant[value=0]()
  %1230 : int = prim::Constant[value=1]()
  %k12.1 : Tensor(*, *, *) = aten::transpose(%1234, %1229, %1230)
  %1226 : int = prim::Constant[value=0]()
  %1227 : Tensor = aten::contiguous(%1261, %1226)
  %1222 : int = prim::Constant[value=-1]()
  %1224 : int[] = prim::ListConstruct(%1222, %1249, %1248)
  %1221 : Tensor(*, *, *) = aten::view(%1227, %1224)
  %1216 : int = prim::Constant[value=0]()
  %1217 : int = prim::Constant[value=1]()
  %v12.1 : Tensor(*, *, *) = aten::transpose(%1221, %1216, %1217)
  %1212 : int = prim::Constant[value=1]()
  %1213 : int = prim::Constant[value=2]()
  %1214 : Tensor(*, *, *) = aten::transpose(%k12.1, %1212, %1213)
  %attn_weights35.1 : Tensor(*, *, *) = aten::bmm(%q19.1, %1214)
  %1207 : int[] = prim::ListConstruct(%bsz5.1, %1250, %tgt_len5.1, %src_len5.1)
  %attn_weights36.1 : Tensor(*, *, *, *) = aten::view(%attn_weights35.1, %1207)
  %1201 : float = prim::Constant[value=-inf]()
  %attn_weights37.1 : Tensor = aten::masked_fill(%attn_weights36.1, %2483, %1201)
  %1199 : int[] = prim::ListConstruct(%1249, %tgt_len5.1, %src_len5.1)
  %attn_weights38.1 : Tensor(*, *, *) = aten::view(%attn_weights37.1, %1199)
  %1191 : int = prim::Constant[value=-1]()
  %1192 : int = prim::Constant[value=6]()
  %ret5.2 : Tensor = aten::softmax(%attn_weights38.1, %1191, %1192)
  %attn_weights39.1 : Tensor = aten::type_as(%ret5.2, %attn_weights38.1)
  %1187 : ClassType<dropout> = prim::GetAttr[name="dropout"](%1280)
  %1186 : bool = prim::GetAttr[name="training"](%1187)
  %1182 : float = prim::Constant[value=0.1]()
  %attn_weights40.2 : Tensor = aten::dropout(%attn_weights39.1, %1182, %1186)
  %attn11.1 : Tensor(*, *, *) = aten::bmm(%attn_weights40.2, %v12.1)
  %1175 : int = prim::Constant[value=0]()
  %1176 : int = prim::Constant[value=1]()
  %1177 : Tensor(*, *, *) = aten::transpose(%attn11.1, %1175, %1176)
  %1172 : int = prim::Constant[value=0]()
  %1173 : Tensor(*, *, *) = aten::contiguous(%1177, %1172)
  %1170 : int[] = prim::ListConstruct(%tgt_len5.1, %bsz5.1, %embed_dim5.1)
  %attn12.1 : Tensor(*, *, *) = aten::view(%1173, %1170)
  %1163 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%1280)
  %1161 : Float(*, *) = prim::GetAttr[name="weight"](%1163)
  %1160 : Float(*) = prim::GetAttr[name="bias"](%1163)
  %1158 : Float(*, *) = aten::t(%1161)
  %output49.1 : Tensor(*, *, *) = aten::matmul(%attn12.1, %1158)
  %1152 : int = prim::Constant[value=1]()
  %output50.1 : Tensor = aten::add_(%output49.1, %1160, %1152)
  %1149 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2570)
  %1148 : bool = prim::GetAttr[name="training"](%1149)
  %1144 : float = prim::Constant[value=0.1]()
  %attention12.2 : Tensor = aten::dropout(%output50.1, %1144, %1148)
  %1141 : int = prim::Constant[value=1]()
  %biased_input11.1 : Tensor = aten::add(%encoded5.1, %attention12.2, %1141)
  %1138 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2570)
  %1137 : Float(*) = prim::GetAttr[name="weight"](%1138)
  %1136 : Float(*) = prim::GetAttr[name="bias"](%1138)
  %1129 : int[] = prim::Constant[value=[768]]()
  %1132 : float = prim::Constant[value=1e-05]()
  %1133 : bool = prim::Constant[value=1]()
  %biased_input12.1 : Tensor = aten::layer_norm(%biased_input11.1, %1129, %1137, %1136, %1132, %1133)
  %1127 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2570)
  %1126 : ClassType<mlp> = prim::GetAttr[name="mlp"](%1127)
  %1124 : ClassType<_0> = prim::GetAttr[name="0"](%1126)
  %1123 : ClassType<_2> = prim::GetAttr[name="2"](%1126)
  %1122 : ClassType<_3> = prim::GetAttr[name="3"](%1126)
  %1121 : ClassType<_4> = prim::GetAttr[name="4"](%1126)
  %1119 : Float(*, *) = prim::GetAttr[name="weight"](%1124)
  %1118 : Float(*) = prim::GetAttr[name="bias"](%1124)
  %1114 : int = prim::Constant[value=2]()
  %1115 : int = prim::Constant[value=1]()
  %input25 : Tensor = glow::fused_linear(%biased_input12.1, %1119, %1118, %1114, %1115)
  %1110 : bool = prim::Constant[value=0]()
  %1111 : FloatTensor = aten::_cast_Float(%input25, %1110)
  %1109 : FloatTensor = aten::gelu(%1111)
  %input26.1 : Tensor = aten::type_as(%1109, %input25)
  %1104 : bool = prim::GetAttr[name="training"](%1123)
  %1100 : float = prim::Constant[value=0.1]()
  %input27.2 : Tensor = aten::dropout(%input26.1, %1100, %1104)
  %1098 : Float(*, *) = prim::GetAttr[name="weight"](%1122)
  %1097 : Float(*) = prim::GetAttr[name="bias"](%1122)
  %1093 : int = prim::Constant[value=2]()
  %1094 : int = prim::Constant[value=1]()
  %input28 : Tensor = glow::fused_linear(%input27.2, %1098, %1097, %1093, %1094)
  %1089 : bool = prim::GetAttr[name="training"](%1121)
  %1085 : float = prim::Constant[value=0.1]()
  %bias61.2 : Tensor = aten::dropout(%input28, %1085, %1089)
  %1082 : int = prim::Constant[value=1]()
  %biased5.1 : Tensor = aten::add(%biased_input12.1, %bias61.2, %1082)
  %1079 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2570)
  %1077 : Float(*) = prim::GetAttr[name="weight"](%1079)
  %1076 : Float(*) = prim::GetAttr[name="bias"](%1079)
  %1069 : int[] = prim::Constant[value=[768]]()
  %1072 : float = prim::Constant[value=1e-05]()
  %1073 : bool = prim::Constant[value=1]()
  %encoded6.1 : Tensor = aten::layer_norm(%biased5.1, %1069, %1077, %1076, %1072, %1073)
  %1067 : ClassType<attention> = prim::GetAttr[name="attention"](%2569)
  %1066 : int[] = aten::size(%encoded6.1)
  %tgt_len6.1 : int, %bsz6.1 : int, %embed_dim6.1 : int = prim::ListUnpack(%1066)
  %1061 : int[] = aten::size(%208)
  %mask_bsz6.1 : int, %src_len6.1 : int = prim::ListUnpack(%1061)
  %1057 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%1067)
  %1056 : Float(*, *) = prim::GetAttr[name="weight"](%1057)
  %1055 : Float(*) = prim::GetAttr[name="bias"](%1057)
  %1051 : int = prim::Constant[value=2]()
  %1052 : int = prim::Constant[value=1]()
  %projection6 : Tensor = glow::fused_linear(%encoded6.1, %1056, %1055, %1051, %1052)
  %1046 : Tensor, %1047 : Tensor, %1048 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection6)
  %1044 : float = prim::GetAttr[name="scaling"](%1067)
  %q21.1 : Tensor = aten::mul_(%1046, %1044)
  %1039 : int = prim::Constant[value=0]()
  %1040 : Tensor = aten::contiguous(%q21.1, %1039)
  %1037 : int = prim::GetAttr[name="num_heads"](%1067)
  %1036 : int = aten::mul(%bsz6.1, %1037)
  %1035 : int = prim::GetAttr[name="head_dim"](%1067)
  %1034 : int[] = prim::ListConstruct(%tgt_len6.1, %1036, %1035)
  %1033 : Tensor(*, *, *) = aten::view(%1040, %1034)
  %1028 : int = prim::Constant[value=0]()
  %1029 : int = prim::Constant[value=1]()
  %q22.1 : Tensor(*, *, *) = aten::transpose(%1033, %1028, %1029)
  %1025 : int = prim::Constant[value=0]()
  %1026 : Tensor = aten::contiguous(%1047, %1025)
  %1022 : int = prim::Constant[value=-1]()
  %1023 : int[] = prim::ListConstruct(%1022, %1036, %1035)
  %1021 : Tensor(*, *, *) = aten::view(%1026, %1023)
  %1016 : int = prim::Constant[value=0]()
  %1017 : int = prim::Constant[value=1]()
  %k14.1 : Tensor(*, *, *) = aten::transpose(%1021, %1016, %1017)
  %1013 : int = prim::Constant[value=0]()
  %1014 : Tensor = aten::contiguous(%1048, %1013)
  %1009 : int = prim::Constant[value=-1]()
  %1011 : int[] = prim::ListConstruct(%1009, %1036, %1035)
  %1008 : Tensor(*, *, *) = aten::view(%1014, %1011)
  %1003 : int = prim::Constant[value=0]()
  %1004 : int = prim::Constant[value=1]()
  %v14.1 : Tensor(*, *, *) = aten::transpose(%1008, %1003, %1004)
  %999 : int = prim::Constant[value=1]()
  %1000 : int = prim::Constant[value=2]()
  %1001 : Tensor(*, *, *) = aten::transpose(%k14.1, %999, %1000)
  %attn_weights41.1 : Tensor(*, *, *) = aten::bmm(%q22.1, %1001)
  %994 : int[] = prim::ListConstruct(%bsz6.1, %1037, %tgt_len6.1, %src_len6.1)
  %attn_weights42.1 : Tensor(*, *, *, *) = aten::view(%attn_weights41.1, %994)
  %988 : float = prim::Constant[value=-inf]()
  %attn_weights43.1 : Tensor = aten::masked_fill(%attn_weights42.1, %2483, %988)
  %986 : int[] = prim::ListConstruct(%1036, %tgt_len6.1, %src_len6.1)
  %attn_weights44.1 : Tensor(*, *, *) = aten::view(%attn_weights43.1, %986)
  %978 : int = prim::Constant[value=-1]()
  %979 : int = prim::Constant[value=6]()
  %ret6.2 : Tensor = aten::softmax(%attn_weights44.1, %978, %979)
  %attn_weights45.1 : Tensor = aten::type_as(%ret6.2, %attn_weights44.1)
  %974 : ClassType<dropout> = prim::GetAttr[name="dropout"](%1067)
  %973 : bool = prim::GetAttr[name="training"](%974)
  %969 : float = prim::Constant[value=0.1]()
  %attn_weights46.2 : Tensor = aten::dropout(%attn_weights45.1, %969, %973)
  %attn13.1 : Tensor(*, *, *) = aten::bmm(%attn_weights46.2, %v14.1)
  %962 : int = prim::Constant[value=0]()
  %963 : int = prim::Constant[value=1]()
  %964 : Tensor(*, *, *) = aten::transpose(%attn13.1, %962, %963)
  %959 : int = prim::Constant[value=0]()
  %960 : Tensor(*, *, *) = aten::contiguous(%964, %959)
  %957 : int[] = prim::ListConstruct(%tgt_len6.1, %bsz6.1, %embed_dim6.1)
  %attn14.1 : Tensor(*, *, *) = aten::view(%960, %957)
  %950 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%1067)
  %948 : Float(*, *) = prim::GetAttr[name="weight"](%950)
  %947 : Float(*) = prim::GetAttr[name="bias"](%950)
  %945 : Float(*, *) = aten::t(%948)
  %output57.1 : Tensor(*, *, *) = aten::matmul(%attn14.1, %945)
  %939 : int = prim::Constant[value=1]()
  %output58.1 : Tensor = aten::add_(%output57.1, %947, %939)
  %936 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2569)
  %935 : bool = prim::GetAttr[name="training"](%936)
  %931 : float = prim::Constant[value=0.1]()
  %attention14.2 : Tensor = aten::dropout(%output58.1, %931, %935)
  %928 : int = prim::Constant[value=1]()
  %biased_input13.1 : Tensor = aten::add(%encoded6.1, %attention14.2, %928)
  %925 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2569)
  %924 : Float(*) = prim::GetAttr[name="weight"](%925)
  %923 : Float(*) = prim::GetAttr[name="bias"](%925)
  %916 : int[] = prim::Constant[value=[768]]()
  %919 : float = prim::Constant[value=1e-05]()
  %920 : bool = prim::Constant[value=1]()
  %biased_input14.1 : Tensor = aten::layer_norm(%biased_input13.1, %916, %924, %923, %919, %920)
  %914 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2569)
  %913 : ClassType<mlp> = prim::GetAttr[name="mlp"](%914)
  %911 : ClassType<_0> = prim::GetAttr[name="0"](%913)
  %910 : ClassType<_2> = prim::GetAttr[name="2"](%913)
  %909 : ClassType<_3> = prim::GetAttr[name="3"](%913)
  %908 : ClassType<_4> = prim::GetAttr[name="4"](%913)
  %906 : Float(*, *) = prim::GetAttr[name="weight"](%911)
  %905 : Float(*) = prim::GetAttr[name="bias"](%911)
  %901 : int = prim::Constant[value=2]()
  %902 : int = prim::Constant[value=1]()
  %input29 : Tensor = glow::fused_linear(%biased_input14.1, %906, %905, %901, %902)
  %897 : bool = prim::Constant[value=0]()
  %898 : FloatTensor = aten::_cast_Float(%input29, %897)
  %896 : FloatTensor = aten::gelu(%898)
  %input30.1 : Tensor = aten::type_as(%896, %input29)
  %891 : bool = prim::GetAttr[name="training"](%910)
  %887 : float = prim::Constant[value=0.1]()
  %input31.2 : Tensor = aten::dropout(%input30.1, %887, %891)
  %885 : Float(*, *) = prim::GetAttr[name="weight"](%909)
  %884 : Float(*) = prim::GetAttr[name="bias"](%909)
  %880 : int = prim::Constant[value=2]()
  %881 : int = prim::Constant[value=1]()
  %input32 : Tensor = glow::fused_linear(%input31.2, %885, %884, %880, %881)
  %876 : bool = prim::GetAttr[name="training"](%908)
  %872 : float = prim::Constant[value=0.1]()
  %bias70.2 : Tensor = aten::dropout(%input32, %872, %876)
  %869 : int = prim::Constant[value=1]()
  %biased6.1 : Tensor = aten::add(%biased_input14.1, %bias70.2, %869)
  %866 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2569)
  %864 : Float(*) = prim::GetAttr[name="weight"](%866)
  %863 : Float(*) = prim::GetAttr[name="bias"](%866)
  %856 : int[] = prim::Constant[value=[768]]()
  %859 : float = prim::Constant[value=1e-05]()
  %860 : bool = prim::Constant[value=1]()
  %encoded7.1 : Tensor = aten::layer_norm(%biased6.1, %856, %864, %863, %859, %860)
  %854 : ClassType<attention> = prim::GetAttr[name="attention"](%2568)
  %853 : int[] = aten::size(%encoded7.1)
  %tgt_len7.1 : int, %bsz7.1 : int, %embed_dim7.1 : int = prim::ListUnpack(%853)
  %848 : int[] = aten::size(%208)
  %mask_bsz7.1 : int, %src_len7.1 : int = prim::ListUnpack(%848)
  %844 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%854)
  %843 : Float(*, *) = prim::GetAttr[name="weight"](%844)
  %842 : Float(*) = prim::GetAttr[name="bias"](%844)
  %838 : int = prim::Constant[value=2]()
  %839 : int = prim::Constant[value=1]()
  %projection7 : Tensor = glow::fused_linear(%encoded7.1, %843, %842, %838, %839)
  %833 : Tensor, %834 : Tensor, %835 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection7)
  %831 : float = prim::GetAttr[name="scaling"](%854)
  %q24.1 : Tensor = aten::mul_(%833, %831)
  %826 : int = prim::Constant[value=0]()
  %827 : Tensor = aten::contiguous(%q24.1, %826)
  %824 : int = prim::GetAttr[name="num_heads"](%854)
  %823 : int = aten::mul(%bsz7.1, %824)
  %822 : int = prim::GetAttr[name="head_dim"](%854)
  %821 : int[] = prim::ListConstruct(%tgt_len7.1, %823, %822)
  %820 : Tensor(*, *, *) = aten::view(%827, %821)
  %815 : int = prim::Constant[value=0]()
  %816 : int = prim::Constant[value=1]()
  %q25.1 : Tensor(*, *, *) = aten::transpose(%820, %815, %816)
  %812 : int = prim::Constant[value=0]()
  %813 : Tensor = aten::contiguous(%834, %812)
  %809 : int = prim::Constant[value=-1]()
  %810 : int[] = prim::ListConstruct(%809, %823, %822)
  %808 : Tensor(*, *, *) = aten::view(%813, %810)
  %803 : int = prim::Constant[value=0]()
  %804 : int = prim::Constant[value=1]()
  %k16.1 : Tensor(*, *, *) = aten::transpose(%808, %803, %804)
  %800 : int = prim::Constant[value=0]()
  %801 : Tensor = aten::contiguous(%835, %800)
  %796 : int = prim::Constant[value=-1]()
  %798 : int[] = prim::ListConstruct(%796, %823, %822)
  %795 : Tensor(*, *, *) = aten::view(%801, %798)
  %790 : int = prim::Constant[value=0]()
  %791 : int = prim::Constant[value=1]()
  %v16.1 : Tensor(*, *, *) = aten::transpose(%795, %790, %791)
  %786 : int = prim::Constant[value=1]()
  %787 : int = prim::Constant[value=2]()
  %788 : Tensor(*, *, *) = aten::transpose(%k16.1, %786, %787)
  %attn_weights47.1 : Tensor(*, *, *) = aten::bmm(%q25.1, %788)
  %781 : int[] = prim::ListConstruct(%bsz7.1, %824, %tgt_len7.1, %src_len7.1)
  %attn_weights48.1 : Tensor(*, *, *, *) = aten::view(%attn_weights47.1, %781)
  %775 : float = prim::Constant[value=-inf]()
  %attn_weights49.1 : Tensor = aten::masked_fill(%attn_weights48.1, %2483, %775)
  %773 : int[] = prim::ListConstruct(%823, %tgt_len7.1, %src_len7.1)
  %attn_weights50.1 : Tensor(*, *, *) = aten::view(%attn_weights49.1, %773)
  %765 : int = prim::Constant[value=-1]()
  %766 : int = prim::Constant[value=6]()
  %ret7.2 : Tensor = aten::softmax(%attn_weights50.1, %765, %766)
  %attn_weights51.1 : Tensor = aten::type_as(%ret7.2, %attn_weights50.1)
  %761 : ClassType<dropout> = prim::GetAttr[name="dropout"](%854)
  %760 : bool = prim::GetAttr[name="training"](%761)
  %756 : float = prim::Constant[value=0.1]()
  %attn_weights52.2 : Tensor = aten::dropout(%attn_weights51.1, %756, %760)
  %attn15.1 : Tensor(*, *, *) = aten::bmm(%attn_weights52.2, %v16.1)
  %749 : int = prim::Constant[value=0]()
  %750 : int = prim::Constant[value=1]()
  %751 : Tensor(*, *, *) = aten::transpose(%attn15.1, %749, %750)
  %746 : int = prim::Constant[value=0]()
  %747 : Tensor(*, *, *) = aten::contiguous(%751, %746)
  %744 : int[] = prim::ListConstruct(%tgt_len7.1, %bsz7.1, %embed_dim7.1)
  %attn16.1 : Tensor(*, *, *) = aten::view(%747, %744)
  %737 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%854)
  %735 : Float(*, *) = prim::GetAttr[name="weight"](%737)
  %734 : Float(*) = prim::GetAttr[name="bias"](%737)
  %732 : Float(*, *) = aten::t(%735)
  %output65.1 : Tensor(*, *, *) = aten::matmul(%attn16.1, %732)
  %726 : int = prim::Constant[value=1]()
  %output66.1 : Tensor = aten::add_(%output65.1, %734, %726)
  %723 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2568)
  %722 : bool = prim::GetAttr[name="training"](%723)
  %718 : float = prim::Constant[value=0.1]()
  %attention16.2 : Tensor = aten::dropout(%output66.1, %718, %722)
  %715 : int = prim::Constant[value=1]()
  %biased_input15.1 : Tensor = aten::add(%encoded7.1, %attention16.2, %715)
  %712 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2568)
  %711 : Float(*) = prim::GetAttr[name="weight"](%712)
  %710 : Float(*) = prim::GetAttr[name="bias"](%712)
  %703 : int[] = prim::Constant[value=[768]]()
  %706 : float = prim::Constant[value=1e-05]()
  %707 : bool = prim::Constant[value=1]()
  %biased_input16.1 : Tensor = aten::layer_norm(%biased_input15.1, %703, %711, %710, %706, %707)
  %701 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2568)
  %700 : ClassType<mlp> = prim::GetAttr[name="mlp"](%701)
  %698 : ClassType<_0> = prim::GetAttr[name="0"](%700)
  %697 : ClassType<_2> = prim::GetAttr[name="2"](%700)
  %696 : ClassType<_3> = prim::GetAttr[name="3"](%700)
  %695 : ClassType<_4> = prim::GetAttr[name="4"](%700)
  %693 : Float(*, *) = prim::GetAttr[name="weight"](%698)
  %692 : Float(*) = prim::GetAttr[name="bias"](%698)
  %688 : int = prim::Constant[value=2]()
  %689 : int = prim::Constant[value=1]()
  %input33 : Tensor = glow::fused_linear(%biased_input16.1, %693, %692, %688, %689)
  %684 : bool = prim::Constant[value=0]()
  %685 : FloatTensor = aten::_cast_Float(%input33, %684)
  %683 : FloatTensor = aten::gelu(%685)
  %input34.1 : Tensor = aten::type_as(%683, %input33)
  %678 : bool = prim::GetAttr[name="training"](%697)
  %674 : float = prim::Constant[value=0.1]()
  %input35.2 : Tensor = aten::dropout(%input34.1, %674, %678)
  %672 : Float(*, *) = prim::GetAttr[name="weight"](%696)
  %671 : Float(*) = prim::GetAttr[name="bias"](%696)
  %667 : int = prim::Constant[value=2]()
  %668 : int = prim::Constant[value=1]()
  %input36 : Tensor = glow::fused_linear(%input35.2, %672, %671, %667, %668)
  %663 : bool = prim::GetAttr[name="training"](%695)
  %659 : float = prim::Constant[value=0.1]()
  %bias79.2 : Tensor = aten::dropout(%input36, %659, %663)
  %656 : int = prim::Constant[value=1]()
  %biased7.1 : Tensor = aten::add(%biased_input16.1, %bias79.2, %656)
  %653 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2568)
  %651 : Float(*) = prim::GetAttr[name="weight"](%653)
  %650 : Float(*) = prim::GetAttr[name="bias"](%653)
  %643 : int[] = prim::Constant[value=[768]]()
  %646 : float = prim::Constant[value=1e-05]()
  %647 : bool = prim::Constant[value=1]()
  %encoded8.1 : Tensor = aten::layer_norm(%biased7.1, %643, %651, %650, %646, %647)
  %641 : ClassType<attention> = prim::GetAttr[name="attention"](%2567)
  %640 : int[] = aten::size(%encoded8.1)
  %tgt_len8.1 : int, %bsz8.1 : int, %embed_dim8.1 : int = prim::ListUnpack(%640)
  %635 : int[] = aten::size(%208)
  %mask_bsz8.1 : int, %src_len8.1 : int = prim::ListUnpack(%635)
  %631 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%641)
  %630 : Float(*, *) = prim::GetAttr[name="weight"](%631)
  %629 : Float(*) = prim::GetAttr[name="bias"](%631)
  %625 : int = prim::Constant[value=2]()
  %626 : int = prim::Constant[value=1]()
  %projection8 : Tensor = glow::fused_linear(%encoded8.1, %630, %629, %625, %626)
  %620 : Tensor, %621 : Tensor, %622 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection8)
  %618 : float = prim::GetAttr[name="scaling"](%641)
  %q27.1 : Tensor = aten::mul_(%620, %618)
  %613 : int = prim::Constant[value=0]()
  %614 : Tensor = aten::contiguous(%q27.1, %613)
  %611 : int = prim::GetAttr[name="num_heads"](%641)
  %610 : int = aten::mul(%bsz8.1, %611)
  %609 : int = prim::GetAttr[name="head_dim"](%641)
  %608 : int[] = prim::ListConstruct(%tgt_len8.1, %610, %609)
  %607 : Tensor(*, *, *) = aten::view(%614, %608)
  %602 : int = prim::Constant[value=0]()
  %603 : int = prim::Constant[value=1]()
  %q28.1 : Tensor(*, *, *) = aten::transpose(%607, %602, %603)
  %599 : int = prim::Constant[value=0]()
  %600 : Tensor = aten::contiguous(%621, %599)
  %596 : int = prim::Constant[value=-1]()
  %597 : int[] = prim::ListConstruct(%596, %610, %609)
  %595 : Tensor(*, *, *) = aten::view(%600, %597)
  %590 : int = prim::Constant[value=0]()
  %591 : int = prim::Constant[value=1]()
  %k18.1 : Tensor(*, *, *) = aten::transpose(%595, %590, %591)
  %587 : int = prim::Constant[value=0]()
  %588 : Tensor = aten::contiguous(%622, %587)
  %583 : int = prim::Constant[value=-1]()
  %585 : int[] = prim::ListConstruct(%583, %610, %609)
  %582 : Tensor(*, *, *) = aten::view(%588, %585)
  %577 : int = prim::Constant[value=0]()
  %578 : int = prim::Constant[value=1]()
  %v18.1 : Tensor(*, *, *) = aten::transpose(%582, %577, %578)
  %573 : int = prim::Constant[value=1]()
  %574 : int = prim::Constant[value=2]()
  %575 : Tensor(*, *, *) = aten::transpose(%k18.1, %573, %574)
  %attn_weights53.1 : Tensor(*, *, *) = aten::bmm(%q28.1, %575)
  %568 : int[] = prim::ListConstruct(%bsz8.1, %611, %tgt_len8.1, %src_len8.1)
  %attn_weights54.1 : Tensor(*, *, *, *) = aten::view(%attn_weights53.1, %568)
  %562 : float = prim::Constant[value=-inf]()
  %attn_weights55.1 : Tensor = aten::masked_fill(%attn_weights54.1, %2483, %562)
  %560 : int[] = prim::ListConstruct(%610, %tgt_len8.1, %src_len8.1)
  %attn_weights56.1 : Tensor(*, *, *) = aten::view(%attn_weights55.1, %560)
  %552 : int = prim::Constant[value=-1]()
  %553 : int = prim::Constant[value=6]()
  %ret8.2 : Tensor = aten::softmax(%attn_weights56.1, %552, %553)
  %attn_weights57.1 : Tensor = aten::type_as(%ret8.2, %attn_weights56.1)
  %548 : ClassType<dropout> = prim::GetAttr[name="dropout"](%641)
  %547 : bool = prim::GetAttr[name="training"](%548)
  %543 : float = prim::Constant[value=0.1]()
  %attn_weights58.2 : Tensor = aten::dropout(%attn_weights57.1, %543, %547)
  %attn17.1 : Tensor(*, *, *) = aten::bmm(%attn_weights58.2, %v18.1)
  %536 : int = prim::Constant[value=0]()
  %537 : int = prim::Constant[value=1]()
  %538 : Tensor(*, *, *) = aten::transpose(%attn17.1, %536, %537)
  %533 : int = prim::Constant[value=0]()
  %534 : Tensor(*, *, *) = aten::contiguous(%538, %533)
  %531 : int[] = prim::ListConstruct(%tgt_len8.1, %bsz8.1, %embed_dim8.1)
  %attn18.1 : Tensor(*, *, *) = aten::view(%534, %531)
  %524 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%641)
  %522 : Float(*, *) = prim::GetAttr[name="weight"](%524)
  %521 : Float(*) = prim::GetAttr[name="bias"](%524)
  %519 : Float(*, *) = aten::t(%522)
  %output73.1 : Tensor(*, *, *) = aten::matmul(%attn18.1, %519)
  %513 : int = prim::Constant[value=1]()
  %output74.1 : Tensor = aten::add_(%output73.1, %521, %513)
  %510 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2567)
  %509 : bool = prim::GetAttr[name="training"](%510)
  %505 : float = prim::Constant[value=0.1]()
  %attention18.2 : Tensor = aten::dropout(%output74.1, %505, %509)
  %502 : int = prim::Constant[value=1]()
  %biased_input17.1 : Tensor = aten::add(%encoded8.1, %attention18.2, %502)
  %499 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2567)
  %498 : Float(*) = prim::GetAttr[name="weight"](%499)
  %497 : Float(*) = prim::GetAttr[name="bias"](%499)
  %490 : int[] = prim::Constant[value=[768]]()
  %493 : float = prim::Constant[value=1e-05]()
  %494 : bool = prim::Constant[value=1]()
  %biased_input18.1 : Tensor = aten::layer_norm(%biased_input17.1, %490, %498, %497, %493, %494)
  %488 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2567)
  %487 : ClassType<mlp> = prim::GetAttr[name="mlp"](%488)
  %485 : ClassType<_0> = prim::GetAttr[name="0"](%487)
  %484 : ClassType<_2> = prim::GetAttr[name="2"](%487)
  %483 : ClassType<_3> = prim::GetAttr[name="3"](%487)
  %482 : ClassType<_4> = prim::GetAttr[name="4"](%487)
  %480 : Float(*, *) = prim::GetAttr[name="weight"](%485)
  %479 : Float(*) = prim::GetAttr[name="bias"](%485)
  %475 : int = prim::Constant[value=2]()
  %476 : int = prim::Constant[value=1]()
  %input37 : Tensor = glow::fused_linear(%biased_input18.1, %480, %479, %475, %476)
  %471 : bool = prim::Constant[value=0]()
  %472 : FloatTensor = aten::_cast_Float(%input37, %471)
  %470 : FloatTensor = aten::gelu(%472)
  %input38.1 : Tensor = aten::type_as(%470, %input37)
  %465 : bool = prim::GetAttr[name="training"](%484)
  %461 : float = prim::Constant[value=0.1]()
  %input39.2 : Tensor = aten::dropout(%input38.1, %461, %465)
  %459 : Float(*, *) = prim::GetAttr[name="weight"](%483)
  %458 : Float(*) = prim::GetAttr[name="bias"](%483)
  %454 : int = prim::Constant[value=2]()
  %455 : int = prim::Constant[value=1]()
  %input40 : Tensor = glow::fused_linear(%input39.2, %459, %458, %454, %455)
  %450 : bool = prim::GetAttr[name="training"](%482)
  %446 : float = prim::Constant[value=0.1]()
  %bias88.2 : Tensor = aten::dropout(%input40, %446, %450)
  %443 : int = prim::Constant[value=1]()
  %biased8.1 : Tensor = aten::add(%biased_input18.1, %bias88.2, %443)
  %440 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2567)
  %438 : Float(*) = prim::GetAttr[name="weight"](%440)
  %437 : Float(*) = prim::GetAttr[name="bias"](%440)
  %430 : int[] = prim::Constant[value=[768]]()
  %433 : float = prim::Constant[value=1e-05]()
  %434 : bool = prim::Constant[value=1]()
  %encoded9.1 : Tensor = aten::layer_norm(%biased8.1, %430, %438, %437, %433, %434)
  %428 : ClassType<attention> = prim::GetAttr[name="attention"](%2566)
  %427 : int[] = aten::size(%encoded9.1)
  %tgt_len9.1 : int, %bsz9.1 : int, %embed_dim9.1 : int = prim::ListUnpack(%427)
  %422 : int[] = aten::size(%208)
  %mask_bsz9.1 : int, %src_len9.1 : int = prim::ListUnpack(%422)
  %418 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%428)
  %417 : Float(*, *) = prim::GetAttr[name="weight"](%418)
  %416 : Float(*) = prim::GetAttr[name="bias"](%418)
  %412 : int = prim::Constant[value=2]()
  %413 : int = prim::Constant[value=1]()
  %projection9 : Tensor = glow::fused_linear(%encoded9.1, %417, %416, %412, %413)
  %407 : Tensor, %408 : Tensor, %409 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection9)
  %405 : float = prim::GetAttr[name="scaling"](%428)
  %q30.1 : Tensor = aten::mul_(%407, %405)
  %400 : int = prim::Constant[value=0]()
  %401 : Tensor = aten::contiguous(%q30.1, %400)
  %398 : int = prim::GetAttr[name="num_heads"](%428)
  %397 : int = aten::mul(%bsz9.1, %398)
  %396 : int = prim::GetAttr[name="head_dim"](%428)
  %395 : int[] = prim::ListConstruct(%tgt_len9.1, %397, %396)
  %394 : Tensor(*, *, *) = aten::view(%401, %395)
  %389 : int = prim::Constant[value=0]()
  %390 : int = prim::Constant[value=1]()
  %q31.1 : Tensor(*, *, *) = aten::transpose(%394, %389, %390)
  %386 : int = prim::Constant[value=0]()
  %387 : Tensor = aten::contiguous(%408, %386)
  %383 : int = prim::Constant[value=-1]()
  %384 : int[] = prim::ListConstruct(%383, %397, %396)
  %382 : Tensor(*, *, *) = aten::view(%387, %384)
  %377 : int = prim::Constant[value=0]()
  %378 : int = prim::Constant[value=1]()
  %k20.1 : Tensor(*, *, *) = aten::transpose(%382, %377, %378)
  %374 : int = prim::Constant[value=0]()
  %375 : Tensor = aten::contiguous(%409, %374)
  %370 : int = prim::Constant[value=-1]()
  %372 : int[] = prim::ListConstruct(%370, %397, %396)
  %369 : Tensor(*, *, *) = aten::view(%375, %372)
  %364 : int = prim::Constant[value=0]()
  %365 : int = prim::Constant[value=1]()
  %v20.1 : Tensor(*, *, *) = aten::transpose(%369, %364, %365)
  %360 : int = prim::Constant[value=1]()
  %361 : int = prim::Constant[value=2]()
  %362 : Tensor(*, *, *) = aten::transpose(%k20.1, %360, %361)
  %attn_weights59.1 : Tensor(*, *, *) = aten::bmm(%q31.1, %362)
  %355 : int[] = prim::ListConstruct(%bsz9.1, %398, %tgt_len9.1, %src_len9.1)
  %attn_weights60.1 : Tensor(*, *, *, *) = aten::view(%attn_weights59.1, %355)
  %349 : float = prim::Constant[value=-inf]()
  %attn_weights61.1 : Tensor = aten::masked_fill(%attn_weights60.1, %2483, %349)
  %347 : int[] = prim::ListConstruct(%397, %tgt_len9.1, %src_len9.1)
  %attn_weights62.1 : Tensor(*, *, *) = aten::view(%attn_weights61.1, %347)
  %339 : int = prim::Constant[value=-1]()
  %340 : int = prim::Constant[value=6]()
  %ret9.2 : Tensor = aten::softmax(%attn_weights62.1, %339, %340)
  %attn_weights63.1 : Tensor = aten::type_as(%ret9.2, %attn_weights62.1)
  %335 : ClassType<dropout> = prim::GetAttr[name="dropout"](%428)
  %334 : bool = prim::GetAttr[name="training"](%335)
  %330 : float = prim::Constant[value=0.1]()
  %attn_weights64.2 : Tensor = aten::dropout(%attn_weights63.1, %330, %334)
  %attn19.1 : Tensor(*, *, *) = aten::bmm(%attn_weights64.2, %v20.1)
  %323 : int = prim::Constant[value=0]()
  %324 : int = prim::Constant[value=1]()
  %325 : Tensor(*, *, *) = aten::transpose(%attn19.1, %323, %324)
  %320 : int = prim::Constant[value=0]()
  %321 : Tensor(*, *, *) = aten::contiguous(%325, %320)
  %318 : int[] = prim::ListConstruct(%tgt_len9.1, %bsz9.1, %embed_dim9.1)
  %attn20.1 : Tensor(*, *, *) = aten::view(%321, %318)
  %311 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%428)
  %309 : Float(*, *) = prim::GetAttr[name="weight"](%311)
  %308 : Float(*) = prim::GetAttr[name="bias"](%311)
  %306 : Float(*, *) = aten::t(%309)
  %output81.1 : Tensor(*, *, *) = aten::matmul(%attn20.1, %306)
  %300 : int = prim::Constant[value=1]()
  %output82.1 : Tensor = aten::add_(%output81.1, %308, %300)
  %297 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2566)
  %296 : bool = prim::GetAttr[name="training"](%297)
  %292 : float = prim::Constant[value=0.1]()
  %attention20.2 : Tensor = aten::dropout(%output82.1, %292, %296)
  %289 : int = prim::Constant[value=1]()
  %biased_input19.1 : Tensor = aten::add(%encoded9.1, %attention20.2, %289)
  %286 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2566)
  %285 : Float(*) = prim::GetAttr[name="weight"](%286)
  %284 : Float(*) = prim::GetAttr[name="bias"](%286)
  %277 : int[] = prim::Constant[value=[768]]()
  %280 : float = prim::Constant[value=1e-05]()
  %281 : bool = prim::Constant[value=1]()
  %biased_input20.1 : Tensor = aten::layer_norm(%biased_input19.1, %277, %285, %284, %280, %281)
  %275 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2566)
  %274 : ClassType<mlp> = prim::GetAttr[name="mlp"](%275)
  %272 : ClassType<_0> = prim::GetAttr[name="0"](%274)
  %271 : ClassType<_2> = prim::GetAttr[name="2"](%274)
  %270 : ClassType<_3> = prim::GetAttr[name="3"](%274)
  %269 : ClassType<_4> = prim::GetAttr[name="4"](%274)
  %267 : Float(*, *) = prim::GetAttr[name="weight"](%272)
  %266 : Float(*) = prim::GetAttr[name="bias"](%272)
  %262 : int = prim::Constant[value=2]()
  %263 : int = prim::Constant[value=1]()
  %input41 : Tensor = glow::fused_linear(%biased_input20.1, %267, %266, %262, %263)
  %258 : bool = prim::Constant[value=0]()
  %259 : FloatTensor = aten::_cast_Float(%input41, %258)
  %257 : FloatTensor = aten::gelu(%259)
  %input42.1 : Tensor = aten::type_as(%257, %input41)
  %252 : bool = prim::GetAttr[name="training"](%271)
  %248 : float = prim::Constant[value=0.1]()
  %input43.2 : Tensor = aten::dropout(%input42.1, %248, %252)
  %246 : Float(*, *) = prim::GetAttr[name="weight"](%270)
  %245 : Float(*) = prim::GetAttr[name="bias"](%270)
  %241 : int = prim::Constant[value=2]()
  %242 : int = prim::Constant[value=1]()
  %input44 : Tensor = glow::fused_linear(%input43.2, %246, %245, %241, %242)
  %237 : bool = prim::GetAttr[name="training"](%269)
  %233 : float = prim::Constant[value=0.1]()
  %bias97.2 : Tensor = aten::dropout(%input44, %233, %237)
  %230 : int = prim::Constant[value=1]()
  %biased9.1 : Tensor = aten::add(%biased_input20.1, %bias97.2, %230)
  %227 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2566)
  %225 : Float(*) = prim::GetAttr[name="weight"](%227)
  %224 : Float(*) = prim::GetAttr[name="bias"](%227)
  %217 : int[] = prim::Constant[value=[768]]()
  %220 : float = prim::Constant[value=1e-05]()
  %221 : bool = prim::Constant[value=1]()
  %encoded10.1 : Tensor = aten::layer_norm(%biased9.1, %217, %225, %224, %220, %221)
  %215 : ClassType<attention> = prim::GetAttr[name="attention"](%2565)
  %214 : int[] = aten::size(%encoded10.1)
  %tgt_len10.1 : int, %bsz10.1 : int, %embed_dim10.1 : int = prim::ListUnpack(%214)
  %209 : int[] = aten::size(%208)
  %mask_bsz10.1 : int, %src_len10.1 : int = prim::ListUnpack(%209)
  %204 : ClassType<input_projection> = prim::GetAttr[name="input_projection"](%215)
  %203 : Float(*, *) = prim::GetAttr[name="weight"](%204)
  %202 : Float(*) = prim::GetAttr[name="bias"](%204)
  %198 : int = prim::Constant[value=2]()
  %199 : int = prim::Constant[value=1]()
  %projection10 : Tensor = glow::fused_linear(%encoded10.1, %203, %202, %198, %199)
  %193 : Tensor, %194 : Tensor, %195 : Tensor = prim::ConstantChunk[chunks=3, dim=-1](%projection10)
  %191 : float = prim::GetAttr[name="scaling"](%215)
  %q33.1 : Tensor = aten::mul_(%193, %191)
  %186 : int = prim::Constant[value=0]()
  %187 : Tensor = aten::contiguous(%q33.1, %186)
  %184 : int = prim::GetAttr[name="num_heads"](%215)
  %183 : int = aten::mul(%bsz10.1, %184)
  %182 : int = prim::GetAttr[name="head_dim"](%215)
  %181 : int[] = prim::ListConstruct(%tgt_len10.1, %183, %182)
  %180 : Tensor(*, *, *) = aten::view(%187, %181)
  %175 : int = prim::Constant[value=0]()
  %176 : int = prim::Constant[value=1]()
  %q34.1 : Tensor(*, *, *) = aten::transpose(%180, %175, %176)
  %172 : int = prim::Constant[value=0]()
  %173 : Tensor = aten::contiguous(%194, %172)
  %169 : int = prim::Constant[value=-1]()
  %170 : int[] = prim::ListConstruct(%169, %183, %182)
  %168 : Tensor(*, *, *) = aten::view(%173, %170)
  %163 : int = prim::Constant[value=0]()
  %164 : int = prim::Constant[value=1]()
  %k22.1 : Tensor(*, *, *) = aten::transpose(%168, %163, %164)
  %160 : int = prim::Constant[value=0]()
  %161 : Tensor = aten::contiguous(%195, %160)
  %156 : int = prim::Constant[value=-1]()
  %158 : int[] = prim::ListConstruct(%156, %183, %182)
  %155 : Tensor(*, *, *) = aten::view(%161, %158)
  %150 : int = prim::Constant[value=0]()
  %151 : int = prim::Constant[value=1]()
  %v22.1 : Tensor(*, *, *) = aten::transpose(%155, %150, %151)
  %146 : int = prim::Constant[value=1]()
  %147 : int = prim::Constant[value=2]()
  %148 : Tensor(*, *, *) = aten::transpose(%k22.1, %146, %147)
  %attn_weights65.1 : Tensor(*, *, *) = aten::bmm(%q34.1, %148)
  %141 : int[] = prim::ListConstruct(%bsz10.1, %184, %tgt_len10.1, %src_len10.1)
  %attn_weights66.1 : Tensor(*, *, *, *) = aten::view(%attn_weights65.1, %141)
  %135 : float = prim::Constant[value=-inf]()
  %attn_weights67.1 : Tensor = aten::masked_fill(%attn_weights66.1, %2483, %135)
  %132 : int[] = prim::ListConstruct(%183, %tgt_len10.1, %src_len10.1)
  %attn_weights68.1 : Tensor(*, *, *) = aten::view(%attn_weights67.1, %132)
  %124 : int = prim::Constant[value=-1]()
  %125 : int = prim::Constant[value=6]()
  %ret10.2 : Tensor = aten::softmax(%attn_weights68.1, %124, %125)
  %attn_weights69.1 : Tensor = aten::type_as(%ret10.2, %attn_weights68.1)
  %120 : ClassType<dropout> = prim::GetAttr[name="dropout"](%215)
  %119 : bool = prim::GetAttr[name="training"](%120)
  %115 : float = prim::Constant[value=0.1]()
  %attn_weights70.2 : Tensor = aten::dropout(%attn_weights69.1, %115, %119)
  %attn21.1 : Tensor(*, *, *) = aten::bmm(%attn_weights70.2, %v22.1)
  %108 : int = prim::Constant[value=0]()
  %109 : int = prim::Constant[value=1]()
  %110 : Tensor(*, *, *) = aten::transpose(%attn21.1, %108, %109)
  %105 : int = prim::Constant[value=0]()
  %106 : Tensor(*, *, *) = aten::contiguous(%110, %105)
  %103 : int[] = prim::ListConstruct(%tgt_len10.1, %bsz10.1, %embed_dim10.1)
  %attn22.1 : Tensor(*, *, *) = aten::view(%106, %103)
  %96 : ClassType<output_projection> = prim::GetAttr[name="output_projection"](%215)
  %94 : Float(*, *) = prim::GetAttr[name="weight"](%96)
  %93 : Float(*) = prim::GetAttr[name="bias"](%96)
  %91 : Float(*, *) = aten::t(%94)
  %output89.1 : Tensor(*, *, *) = aten::matmul(%attn22.1, %91)
  %85 : int = prim::Constant[value=1]()
  %output90.1 : Tensor = aten::add_(%output89.1, %93, %85)
  %82 : ClassType<dropout> = prim::GetAttr[name="dropout"](%2565)
  %81 : bool = prim::GetAttr[name="training"](%82)
  %77 : float = prim::Constant[value=0.1]()
  %attention22.2 : Tensor = aten::dropout(%output90.1, %77, %81)
  %74 : int = prim::Constant[value=1]()
  %biased_input21.1 : Tensor = aten::add(%encoded10.1, %attention22.2, %74)
  %71 : ClassType<attention_layer_norm> = prim::GetAttr[name="attention_layer_norm"](%2565)
  %70 : Float(*) = prim::GetAttr[name="weight"](%71)
  %69 : Float(*) = prim::GetAttr[name="bias"](%71)
  %62 : int[] = prim::Constant[value=[768]]()
  %65 : float = prim::Constant[value=1e-05]()
  %66 : bool = prim::Constant[value=1]()
  %biased_input22.1 : Tensor = aten::layer_norm(%biased_input21.1, %62, %70, %69, %65, %66)
  %60 : ClassType<residual_mlp> = prim::GetAttr[name="residual_mlp"](%2565)
  %59 : ClassType<mlp> = prim::GetAttr[name="mlp"](%60)
  %57 : ClassType<_0> = prim::GetAttr[name="0"](%59)
  %56 : ClassType<_2> = prim::GetAttr[name="2"](%59)
  %55 : ClassType<_3> = prim::GetAttr[name="3"](%59)
  %54 : ClassType<_4> = prim::GetAttr[name="4"](%59)
  %52 : Float(*, *) = prim::GetAttr[name="weight"](%57)
  %51 : Float(*) = prim::GetAttr[name="bias"](%57)
  %47 : int = prim::Constant[value=2]()
  %48 : int = prim::Constant[value=1]()
  %input45 : Tensor = glow::fused_linear(%biased_input22.1, %52, %51, %47, %48)
  %43 : bool = prim::Constant[value=0]()
  %44 : FloatTensor = aten::_cast_Float(%input45, %43)
  %42 : FloatTensor = aten::gelu(%44)
  %input46.1 : Tensor = aten::type_as(%42, %input45)
  %37 : bool = prim::GetAttr[name="training"](%56)
  %33 : float = prim::Constant[value=0.1]()
  %input47.2 : Tensor = aten::dropout(%input46.1, %33, %37)
  %31 : Float(*, *) = prim::GetAttr[name="weight"](%55)
  %30 : Float(*) = prim::GetAttr[name="bias"](%55)
  %26 : int = prim::Constant[value=2]()
  %27 : int = prim::Constant[value=1]()
  %input48 : Tensor = glow::fused_linear(%input47.2, %31, %30, %26, %27)
  %22 : bool = prim::GetAttr[name="training"](%54)
  %18 : float = prim::Constant[value=0.1]()
  %bias106.2 : Tensor = aten::dropout(%input48, %18, %22)
  %15 : int = prim::Constant[value=1]()
  %biased10.1 : Tensor = aten::add(%biased_input22.1, %bias106.2, %15)
  %12 : ClassType<final_layer_norm> = prim::GetAttr[name="final_layer_norm"](%2565)
  %10 : Float(*) = prim::GetAttr[name="weight"](%12)
  %9 : Float(*) = prim::GetAttr[name="bias"](%12)
  %1 : int[] = prim::Constant[value=[768]]()
  %4 : float = prim::Constant[value=1e-05]()
  %5 : bool = prim::Constant[value=1]()
  %encoded11.1 : Tensor = aten::layer_norm(%biased10.1, %1, %10, %9, %4, %5)
  %7 : int[] = prim::Constant[value=[768]]()
  return (%encoded11.1, %encoded10.1, %encoded9.1, %encoded8.1, %encoded7.1, %encoded6.1, %encoded5.1, %encoded4.1, %encoded3.1, %encoded2.1, %encoded1.1, %encoded0.1, %encoded.1)